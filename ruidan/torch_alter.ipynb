{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import init\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
    "\n",
    "    def __init__(self, token_to_idx=None, mask_token=\"<MASK>\", unk_token=\"<UNK>\", num_token='<NUM>'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
    "            mask_token (str): the MASK token to add into the Vocabulary; indicates\n",
    "                a position that will not be used in updating the model's parameters\n",
    "            add_unk (bool): a flag that indicates whether to add the UNK token\n",
    "            unk_token (str): the UNK token to add into the Vocabulary\n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "\n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "\n",
    "        self._unk_token = unk_token\n",
    "        self._mask_token = mask_token\n",
    "        self._num_token = num_token\n",
    "        \n",
    "        self.unk_index = self.add_token(unk_token) \n",
    "        self.num_index = self.add_token(num_token)\n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        \n",
    "    def to_serializable(self):\n",
    "        \"\"\" returns a dictionary that can be serialized \"\"\"\n",
    "        return {'token_to_idx': self._token_to_idx, \n",
    "                'add_unk': self._add_unk, \n",
    "                'unk_token': self._unk_token, \n",
    "                'mask_token': self._mask_token,\n",
    "                'num_token': self._num_token,\n",
    "               }\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        \"\"\" instantiates the Vocabulary from a serialized dictionary \"\"\"\n",
    "        return cls(**contents)\n",
    "\n",
    "    def add_token(self, token):\n",
    "        \"\"\"Update mapping dicts based on the token.\n",
    "\n",
    "        Args:\n",
    "            token (str): the item to add into the Vocabulary\n",
    "        Returns:\n",
    "            index (int): the integer corresponding to the token\n",
    "        \"\"\"\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "            \n",
    "    def add_many(self, tokens):\n",
    "        \"\"\"Add a list of tokens into the Vocabulary\n",
    "        \n",
    "        Args:\n",
    "            tokens (list): a list of string tokens\n",
    "        Returns:\n",
    "            indices (list): a list of indices corresponding to the tokens\n",
    "        \"\"\"\n",
    "        return [self.add_token(token) for token in tokens]\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "          or the UNK index if token isn't present.\n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        Notes:\n",
    "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
    "              for the UNK functionality \n",
    "        \"\"\"\n",
    "        if self.is_number(token):\n",
    "            return self.num_index\n",
    "            \n",
    "        return self._token_to_idx.get(token, self.unk_index)\n",
    "    \n",
    "    def is_number(self, token):\n",
    "        num_regex = re.compile('^[+-]?[0-9]+\\.?[0-9]*$')\n",
    "\n",
    "        return bool(num_regex.match(token))\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"Return the token associated with the index\n",
    "        \n",
    "        Args: \n",
    "            index (int): the index to look up\n",
    "        Returns:\n",
    "            token (str): the token corresponding to the index\n",
    "        Raises:\n",
    "            KeyError: if the index is not in the Vocabulary\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectorizer(object):\n",
    "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"    \n",
    "    def __init__(self, cbow_vocab):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            cbow_vocab (Vocabulary): maps words to integers\n",
    "        \"\"\"\n",
    "        self.cbow_vocab = cbow_vocab\n",
    "\n",
    "    def vectorize(self, context, vector_length=-1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            context (str): the string of words separated by a space\n",
    "            vector_length (int): an argument for forcing the length of index vector\n",
    "        \"\"\"\n",
    "\n",
    "        indices = [self.cbow_vocab.lookup_token(token) for token in context.split(' ')]\n",
    "        if vector_length < 0:\n",
    "            vector_length = len(indices)\n",
    "\n",
    "        out_vector = np.zeros(vector_length, dtype=np.int64)\n",
    "        out_vector[-len(indices):] = indices\n",
    "        out_vector[:-len(indices)] = self.cbow_vocab.mask_index\n",
    "\n",
    "        return out_vector\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, cbow_df):\n",
    "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
    "        \n",
    "        Args:\n",
    "            cbow_df (pandas.DataFrame): the target dataset\n",
    "        Returns:\n",
    "            an instance of the CBOWVectorizer\n",
    "        \"\"\"\n",
    "        cbow_vocab = Vocabulary()\n",
    "        for index, row in cbow_df.iterrows():\n",
    "            for token in row.context.split(' '):\n",
    "                cbow_vocab.add_token(token)\n",
    "            cbow_vocab.add_token(row.target)\n",
    "            \n",
    "        return cls(cbow_vocab)\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        cbow_vocab = \\\n",
    "            Vocabulary.from_serializable(contents['cbow_vocab'])\n",
    "        return cls(cbow_vocab=cbow_vocab)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        return {'cbow_vocab': self.cbow_vocab.to_serializable()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, train_df, test_df, vectorizer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            cbow_df (pandas.DataFrame): the dataset\n",
    "            vectorizer (CBOWVectorizer): vectorizer instatiated from dataset\n",
    "        \"\"\"\n",
    "        self.train_df = train_df\n",
    "        self.train_size = len(train_df)\n",
    "        \n",
    "        self.test_df = test_df\n",
    "        self.test_size = len(test_df)\n",
    "        \n",
    "        self._vectorizer = vectorizer\n",
    "        \n",
    "        measure_len = lambda context: len(context.split(\" \"))\n",
    "        self._max_seq_length = max(map(measure_len, train_df.sentence))\n",
    "        \n",
    "        self._lookup_dict = {\n",
    "            'train': (self.train_df, self.train_size),\n",
    "            'test': (self.test_df, self.test_size)\n",
    "        }\n",
    "        \n",
    "        self.set_split('train')\n",
    "        \n",
    "    @property\n",
    "    def mex_seq_length(self):\n",
    "        return self._max_seq_length\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        \"\"\" selects the splits in the dataset using a column in the dataframe \"\"\"\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "    \n",
    "    def get_vectorizer(self):\n",
    "        \"\"\" returns the vectorizer \"\"\"\n",
    "        return self._vectorizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"the primary entry point method for PyTorch datasets\n",
    "        \n",
    "        Args:\n",
    "            index (int): the index to the data point \n",
    "        Returns:\n",
    "            a dictionary holding the data point's features (x_data) and label (y_target)\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "        target = 0.\n",
    "\n",
    "        context_vector = self._vectorizer.vectorize(row.sentence, self._max_seq_length)\n",
    "\n",
    "        return {\n",
    "            'x_data': context_vector,\n",
    "            'y_target': 0. if self._target_split == 'train' else row.label,\n",
    "        }\n",
    "\n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int)\n",
    "        Returns:\n",
    "            number of batches in the dataset\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=True, device=\"cpu\"): \n",
    "    \"\"\"\n",
    "    A generator function which wraps the PyTorch DataLoader. It will \n",
    "      ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device) \\\n",
    "            if isinstance(data_dict[name], torch.Tensor) else data_dict[name]\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = ' '.join(word.lower() for word in text.split(\" \"))\n",
    "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroids(w2v_model, aspects_count):\n",
    "    \"\"\"\n",
    "        Clustering all word vectors with K-means and returning L2-normalizes\n",
    "        cluster centroids; used for ABAE aspects matrix initialization\n",
    "    \"\"\"\n",
    "\n",
    "    km = MiniBatchKMeans(n_clusters=aspects_count, verbose=0, n_init=100)\n",
    "    m = []\n",
    "\n",
    "    for k in w2v_model.wv.vocab:\n",
    "        m.append(w2v_model.wv[k])\n",
    "\n",
    "    m = np.matrix(m)\n",
    "\n",
    "    km.fit(m)\n",
    "    clusters = km.cluster_centers_\n",
    "\n",
    "    # L2 normalization\n",
    "    norm_aspect_matrix = clusters / np.linalg.norm(clusters, axis=-1, keepdims=True)\n",
    "\n",
    "    return norm_aspect_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(torch.nn.Module):\n",
    "    def __init__(self, wv_dim: int, maxlen: int):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.wv_dim = wv_dim\n",
    "\n",
    "        # max sentence length -- batch 2nd dim size\n",
    "        self.maxlen = maxlen\n",
    "        self.M = Parameter(torch.empty(size=(wv_dim, wv_dim)))\n",
    "        init.kaiming_uniform_(self.M.data)\n",
    "\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.attention_softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_embeddings):\n",
    "        # (b, wv, 1)\n",
    "        mean_embedding = torch.mean(input_embeddings, (1,)).unsqueeze(2)\n",
    "\n",
    "        # (wv, wv) x (b, wv, 1) -> (b, wv, 1)\n",
    "        product_1 = torch.matmul(self.M, mean_embedding)\n",
    "\n",
    "        # (b, maxlen, wv) x (b, wv, 1) -> (b, maxlen, 1)\n",
    "        product_2 = torch.matmul(input_embeddings, product_1).squeeze(2)\n",
    "\n",
    "        results = self.attention_softmax(self.tanh(product_2))\n",
    "\n",
    "        return results\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'wv_dim={}, maxlen={}'.format(self.wv_dim, self.maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ABAE(torch.nn.Module):\n",
    "    \"\"\"\n",
    "        The model described in the paper ``An Unsupervised Neural Attention Model for Aspect Extraction''\n",
    "        by He, Ruidan and  Lee, Wee Sun  and  Ng, Hwee Tou  and  Dahlmeier, Daniel, ACL2017\n",
    "        https://aclweb.org/anthology/papers/P/P17/P17-1036/\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        wv_dim, \n",
    "        asp_count,\n",
    "        ortho_reg, \n",
    "        maxlen, \n",
    "        init_aspects_matrix,\n",
    "        pretrained_embedding,\n",
    "        padding_index,\n",
    "        encoder_only=False,\n",
    "    ):\n",
    "        \"\"\"Initializing the model\n",
    "        \n",
    "        :param wv_dim: word vector size\n",
    "        :param asp_count: number of aspects\n",
    "        :param ortho_reg: coefficient for tuning the ortho-regularizer's influence\n",
    "        :param maxlen: sentence max length taken into account\n",
    "        :param init_aspects_matrix: None or init. matrix for aspects\n",
    "        \"\"\"\n",
    "        super(ABAE, self).__init__()\n",
    "        self.wv_dim = wv_dim\n",
    "        self.asp_count = asp_count\n",
    "        self.ortho = ortho_reg\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(\n",
    "            torch.FloatTensor(pretrained_embedding), \n",
    "            padding_idx=padding_index,\n",
    "        )\n",
    "        \n",
    "        self.attention = SelfAttention(wv_dim, maxlen)\n",
    "        self.linear_transform = torch.nn.Linear(self.wv_dim, self.asp_count)\n",
    "        self.softmax_aspects = torch.nn.Softmax(dim=1)\n",
    "        self.aspects_embeddings = Parameter(torch.empty(size=(wv_dim, asp_count)))\n",
    "\n",
    "        if init_aspects_matrix is None:\n",
    "            torch.nn.init.xavier_uniform(self.aspects_embeddings)\n",
    "        else:\n",
    "            self.aspects_embeddings.data = torch.from_numpy(init_aspects_matrix.T)\n",
    "            \n",
    "        self.encoder_only = encoder_only\n",
    "\n",
    "    def get_aspects_importances(self, text_embeddings):\n",
    "        \"\"\"Takes embeddings of a sentence as input, returns attention weights\n",
    "\n",
    "        \"\"\"\n",
    "        # compute attention scores, looking at text embeddings average\n",
    "        attention_weights = self.attention(text_embeddings)\n",
    "\n",
    "        # multiplying text embeddings by attention scores -- and summing\n",
    "        # (matmul: we sum every word embedding's coordinate with attention weights)\n",
    "        weighted_text_emb = torch.matmul(attention_weights.unsqueeze(1),  # (batch, 1, sentence)\n",
    "                                         text_embeddings  # (batch, sentence, wv_dim)\n",
    "                                         ).squeeze()\n",
    "\n",
    "        # encoding with a simple feed-forward layer (wv_dim) -> (aspects_count)\n",
    "        raw_importances = self.linear_transform(weighted_text_emb)\n",
    "\n",
    "        # computing 'aspects distribution in a sentence'\n",
    "        aspects_importances = self.softmax_aspects(raw_importances)\n",
    "\n",
    "        return attention_weights, aspects_importances, weighted_text_emb\n",
    "\n",
    "    def forward(self, text_embeddings, negative_samples_texts):\n",
    "        \n",
    "        text_embeddings = self.embedding(text_embeddings)\n",
    "\n",
    "        # encoding: words embeddings -> sentence embedding, aspects importances\n",
    "        _, aspects_importances, weighted_text_emb = self.get_aspects_importances(text_embeddings)\n",
    "        \n",
    "        if self.encoder_only:\n",
    "            return aspects_importances\n",
    "        else:\n",
    "            negative_samples_texts = self.embedding(negative_samples_texts)\n",
    "            \n",
    "            # negative samples are averaged\n",
    "            averaged_negative_samples = torch.mean(negative_samples_texts, dim=1)\n",
    "            averaged_negative_samples = torch.mean(averaged_negative_samples, dim=1)\n",
    "            \n",
    "            # decoding: aspects embeddings matrix, aspects_importances -> recovered sentence embedding\n",
    "            recovered_emb = torch.matmul(self.aspects_embeddings, aspects_importances.unsqueeze(2)).squeeze()\n",
    "            \n",
    "            return weighted_text_emb, recovered_emb, averaged_negative_samples\n",
    "\n",
    "    def get_aspect_words(self, w2v_model, topn=10):\n",
    "        words = []\n",
    "\n",
    "        # getting aspects embeddings\n",
    "        aspects = self.aspects_embeddings.cpu().detach().numpy()\n",
    "\n",
    "        # getting scalar products of word embeddings and aspect embeddings;\n",
    "        # to obtain the ``probabilities'', one should also apply softmax\n",
    "        words_scores = w2v_model.wv.vectors.dot(aspects)\n",
    "\n",
    "        for row in range(aspects.shape[1]):\n",
    "            argmax_scalar_products = np.argsort(- words_scores[:, row])[:topn]\n",
    "            words.append([w2v_model.wv.index2word[i] for i in argmax_scalar_products])\n",
    "\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "        \n",
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "\n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['train_loss'][-2:]\n",
    "\n",
    "        # If loss worsened\n",
    "        if loss_t >= train_state['early_stopping_best_val']:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    train_data='preprocessed_data/restaurant/train.txt',\n",
    "    test_data='preprocessed_data/restaurant/test.txt',\n",
    "    test_labels='preprocessed_data/restaurant/test_label.txt',\n",
    "    emb_path='preprocessed_data/restaurant/w2v_embedding',\n",
    "    emb_dim=200,\n",
    "    batch_size=50,\n",
    "    vocab_size=9000,\n",
    "    aspect_size=14,\n",
    "    \n",
    "    epochs=15,\n",
    "    neg_size=20,\n",
    "    maxlen=-1,\n",
    "    ortho_reg=0.1,\n",
    "    \n",
    "    cuda=True,\n",
    "    reload_from_files=False,\n",
    "    learning_rate=1e-4 * 5,\n",
    "    early_stopping_criteria=5,  \n",
    "    catch_keyboard_interrupt=True,\n",
    "    seed=1234,\n",
    "    \n",
    "    save_dir=\"model_storage\",\n",
    "    model_state_file=\"model.pth\",\n",
    ")\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0bfede8a524ff1b5432e93638f4547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=279885.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "279885 sentences\n",
      "Sample: place fancy wouldn go date \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like jeollado like roll sometimes price variet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>like roll tiny order anyway often get order wr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>money dependable fun place get sushi bring fri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>place great deal price food give</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crab roll made real crab imitation crab</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence\n",
       "0  like jeollado like roll sometimes price variet...\n",
       "1  like roll tiny order anyway often get order wr...\n",
       "2  money dependable fun place get sushi bring fri...\n",
       "3                  place great deal price food give \n",
       "4           crab roll made real crab imitation crab "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "with open('preprocessed_data/restaurant/train.txt') as fp:\n",
    "    for line in tqdm(fp.readlines()):\n",
    "        sentences.append(line)\n",
    "        \n",
    "cleaned_sentences = [preprocess_text(sentence) for sentence in sentences]\n",
    "\n",
    "print (len(cleaned_sentences), \"sentences\")\n",
    "print (\"Sample:\", cleaned_sentences[42])\n",
    "\n",
    "train_df = pd.DataFrame(cleaned_sentences, columns=[\"sentence\"])\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b726f7cc484b4226b99f3dec3f486994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1490.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5482c301da3248cca473eab2d6ce675d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1490.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>staff friendliest competent stickler service e...</td>\n",
       "      <td>staff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great group great date great early brunch nigh...</td>\n",
       "      <td>ambience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>like cafe noir dont get wrong jsut people work...</td>\n",
       "      <td>staff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>service terrible wait everything ask several d...</td>\n",
       "      <td>staff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>waitress seems concerned looking good actually...</td>\n",
       "      <td>staff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence     label\n",
       "0  staff friendliest competent stickler service e...     staff\n",
       "1  great group great date great early brunch nigh...  ambience\n",
       "2  like cafe noir dont get wrong jsut people work...     staff\n",
       "3  service terrible wait everything ask several d...     staff\n",
       "4  waitress seems concerned looking good actually...     staff"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "with open('preprocessed_data/restaurant/test.txt') as fp:\n",
    "    for line in tqdm(fp.readlines()):\n",
    "        sentences.append(line)\n",
    "        \n",
    "with open('preprocessed_data/restaurant/test_label.txt') as fp:\n",
    "    for line in tqdm(fp.readlines()):\n",
    "        labels.append(line)\n",
    "        \n",
    "cleaned_sentences = [preprocess_text(sentence) for sentence in sentences]\n",
    "cleaned_labels = [preprocess_text(label.split()[0]) for label in labels]\n",
    "        \n",
    "test_df = pd.DataFrame({'sentence': cleaned_sentences, 'label': cleaned_labels})\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = gensim.models.Word2Vec.load(args.emb_path)\n",
    "token2index_lim = {token: index for index, token in enumerate(w2v.wv.index2word) if index < args.vocab_size}\n",
    "token2index_all = {token: index for index, token in enumerate(w2v.wv.index2word)}\n",
    "vocab = Vocabulary(token2index_lim)\n",
    "vectorizer = Vectorizer(vocab)\n",
    "dataset = Dataset(train_df, test_df , vectorizer)\n",
    "\n",
    "model = ABAE(\n",
    "    wv_dim=args.emb_dim,\n",
    "    asp_count=args.aspect_size,\n",
    "    ortho_reg=args.ortho_reg, \n",
    "    maxlen=dataset.mex_seq_length, \n",
    "    init_aspects_matrix=get_centroids(w2v, args.aspect_size),\n",
    "    pretrained_embedding=w2v.wv.vectors,\n",
    "    padding_index=vocab.mask_index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(args.device)\n",
    "loss_func = nn.TripletMarginLoss(margin=1, swap=False, reduction='mean')\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer=optimizer,\n",
    "    mode='min', \n",
    "    factor=0.5,\n",
    "    patience=1\n",
    ")\n",
    "\n",
    "train_state = make_train_state(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d9c084534746dc955cc542a34b8e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='training routine', max=15.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff58d6dd2654cfc99d8060e55a5f4da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='train', max=5597.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5596 batches, and LR: 0.0005\n",
      "0 chicken sauce tomato onion potato fried mushroom grilled beef salad\n",
      "1 worst dry overpriced top average best buck mediocre cost dollar\n",
      "2 pay money didn dont want leave unless wouldn anything doesn\n",
      "3 u minute asked table manager min seated waiter bill told\n",
      "4 wall room ceiling space window floor wood lit lighting booth\n",
      "5 entree portion course dish fixe prix price appetizer bill menu\n",
      "6 went birthday saturday night friday anniversary week weekend sunday celebrate\n",
      "7 year review worst lived ve citysearch recently ever manager reviewer\n",
      "8 service staff waitstaff server waitress waiter bartender hostess attentive attitude\n",
      "9 time go eat get area year ve week month place\n",
      "10 great excellent good nice perfect delicious amazing wonderful fantastic awesome\n",
      "11 tender perfectly tomato gras wood flavor seasoned sauce presented ingredient\n",
      "12 cream chocolate banana ice apple creme strawberry butter tart de\n",
      "13 cuisine fare authentic american food indian mexican neighborhood japanese fusion\n",
      "Loss: 0.5087922215461731\n",
      "\n",
      "5596 batches, and LR: 0.0005\n",
      "0 sauce chicken tomato onion potato fried mushroom grilled bean beef\n",
      "1 dry worst overpriced top average buck mediocre filet dollar cost\n",
      "2 pay didn money dont want unless leave doesn wouldn anything\n",
      "3 u minute asked table manager waiter min seated waitress bill\n",
      "4 wall room space ceiling window floor lit lighting booth wood\n",
      "5 entree portion course fixe prix dish price menu wine bill\n",
      "6 went birthday saturday night friday week anniversary weekend celebrate sunday\n",
      "7 review year worst citysearch lived ve recently ever reviewer manager\n",
      "8 service staff waitstaff server atmosphere waitress hostess waiter attentive bartender\n",
      "9 time go eat get area ve month year week reservation\n",
      "10 great excellent good perfect nice delicious amazing wonderful awesome fantastic\n",
      "11 tender wood knowledgeable perfectly tomato gras ingredient fresh flavor professional\n",
      "12 cream chocolate ice banana creme apple strawberry tea fruit butter\n",
      "13 cuisine fare american food authentic mexican neighborhood indian bistro fusion\n",
      "Loss: 0.530828595161438\n",
      "\n",
      "5596 batches, and LR: 0.0005\n",
      "0 sauce chicken tomato onion potato fried mushroom grilled bean garlic\n",
      "1 dry worst overpriced top buck filet average dollar mediocre cost\n",
      "2 pay didn dont money want unless doesn wouldn leave anything\n",
      "3 u minute asked table manager waiter min waitress glass water\n",
      "4 wall room space ceiling window lit floor booth lighting wood\n",
      "5 entree portion course fixe prix dish menu price wine bill\n",
      "6 went birthday saturday night week anniversary friday weekend celebrate sunday\n",
      "7 review year worst citysearch reviewer recently lived ever manager ve\n",
      "8 service staff waitstaff atmosphere attentive food hostess server attitude waitress\n",
      "9 go time eat get area reservation ve month wait week\n",
      "10 great excellent good delicious nice perfect amazing awesome best fantastic\n",
      "11 knowledgeable wood tender staff gras tomato professional perfectly ingredient flavor\n",
      "12 cream chocolate ice banana creme apple strawberry tea butter fruit\n",
      "13 cuisine fare american food authentic neighborhood mexican indian bistro japanese\n",
      "Loss: 0.49219611287117004\n",
      "\n",
      "5596 batches, and LR: 0.0005\n",
      "0 sauce chicken tomato onion potato fried mushroom grilled bean garlic\n",
      "1 dry worst overpriced top buck filet dollar average mediocre price\n",
      "2 pay dont didn money want unless wouldn doesn anything leave\n",
      "3 u minute asked table manager waiter min waitress glass water\n",
      "4 wall room space ceiling window lit floor booth lighting wood\n",
      "5 entree portion course fixe prix dish menu price wine bill\n",
      "6 went birthday saturday night week anniversary friday weekend month dined\n",
      "7 review year worst citysearch reviewer manager recently ever lived ve\n",
      "8 service staff waitstaff food atmosphere attentive hostess attitude server ambience\n",
      "9 go eat time reservation area get wait ve month sit\n",
      "10 great excellent good amazing delicious nice perfect awesome best fantastic\n",
      "11 knowledgeable staff wood tender gras tomato professional waitstaff helpful flavor\n",
      "12 cream chocolate ice banana creme apple strawberry tea butter fruit\n",
      "13 cuisine fare american neighborhood food authentic mexican indian bistro restaurant\n",
      "Loss: 0.5036140084266663\n",
      "\n",
      "5596 batches, and LR: 0.0005\n",
      "0 sauce chicken tomato onion potato fried mushroom grilled bean garlic\n",
      "1 dry overpriced worst top buck filet dollar average mediocre price\n",
      "2 pay dont didn money want unless wouldn doesn anything leave\n",
      "3 u minute asked table waiter manager min waitress glass water\n",
      "4 room wall space ceiling window lit floor booth lighting wood\n",
      "5 entree course portion fixe prix menu dish wine price bill\n",
      "6 went birthday saturday night week anniversary friday weekend month dined\n",
      "7 review year worst citysearch reviewer manager recently ever lived ve\n",
      "8 service staff waitstaff food attentive atmosphere hostess attitude rude ambience\n",
      "9 go eat reservation time area get wait ve month sit\n",
      "10 great excellent good amazing delicious nice awesome perfect best fantastic\n",
      "11 staff knowledgeable wood gras tender tomato waitstaff professional flavor helpful\n",
      "12 cream chocolate ice banana creme apple strawberry tea butter fruit\n",
      "13 cuisine fare american neighborhood food authentic mexican indian bistro restaurant\n",
      "Loss: 0.489190936088562\n",
      "\n",
      "5596 batches, and LR: 0.0005\n",
      "0 sauce chicken tomato onion potato mushroom fried grilled bean garlic\n",
      "1 dry overpriced worst top buck filet dollar average mediocre price\n",
      "2 pay dont didn money want unless wouldn doesn anything leave\n",
      "3 u minute asked table waiter manager min waitress glass water\n",
      "4 room wall space ceiling window lit floor booth lighting wood\n",
      "5 entree course portion fixe prix menu dish wine price bill\n",
      "6 went birthday saturday night week anniversary friday weekend month dined\n",
      "7 review year worst citysearch reviewer manager recently ever lived ve\n",
      "8 service staff waitstaff food attentive atmosphere hostess rude attitude prompt\n",
      "9 go eat reservation area time wait get ve sit waiting\n",
      "10 great excellent good amazing delicious nice awesome perfect best fantastic\n",
      "11 staff knowledgeable wood gras tender waitstaff tomato flavor professional helpful\n",
      "12 cream chocolate ice banana creme apple strawberry butter tea fruit\n",
      "13 cuisine fare american neighborhood authentic food mexican indian bistro restaurant\n",
      "Loss: 0.5096991658210754\n",
      "\n",
      "5596 batches, and LR: 0.0005\n",
      "0 sauce chicken tomato onion potato mushroom fried grilled bean garlic\n",
      "1 dry overpriced worst top buck filet dollar average mediocre price\n",
      "2 pay dont didn money want unless wouldn doesn anything leave\n",
      "3 u minute asked table waiter manager min waitress glass water\n",
      "4 room wall space ceiling window lit floor lighting booth wood\n",
      "5 entree course portion fixe prix menu dish wine price bill\n",
      "6 went birthday saturday night week anniversary friday weekend month dined\n",
      "7 review year worst citysearch reviewer manager recently ever lived ve\n",
      "8 service staff waitstaff food attentive atmosphere hostess rude attitude prompt\n",
      "9 go eat reservation area wait time get ve sit waiting\n",
      "10 great excellent good amazing delicious awesome nice perfect best fantastic\n",
      "11 staff knowledgeable wood waitstaff gras tender tomato flavor professional helpful\n",
      "12 cream chocolate ice banana creme apple strawberry butter tea fruit\n",
      "13 cuisine fare american neighborhood food authentic mexican indian bistro restaurant\n",
      "Loss: 0.4277040660381317\n",
      "\n",
      "5596 batches, and LR: 0.0005\n",
      "0 sauce chicken tomato onion potato mushroom fried grilled bean garlic\n",
      "1 dry overpriced worst top filet buck dollar average mediocre price\n",
      "2 pay dont didn money unless want wouldn doesn anything leave\n",
      "3 u minute asked table waiter manager min waitress glass water\n",
      "4 room wall space ceiling window lit floor lighting booth wood\n",
      "5 entree course portion fixe prix menu dish wine price bill\n",
      "6 went birthday saturday night week anniversary weekend friday month dined\n",
      "7 review year worst citysearch reviewer manager recently ever lived ve\n",
      "8 service staff waitstaff food attentive atmosphere rude hostess attitude friendly\n",
      "9 go eat reservation area wait time get sit ve waiting\n",
      "10 great excellent good amazing delicious awesome nice best perfect fantastic\n",
      "11 staff knowledgeable wood waitstaff gras tender tomato flavor professional helpful\n",
      "12 cream chocolate ice banana creme apple strawberry butter tea fruit\n",
      "13 cuisine fare american neighborhood authentic food indian mexican bistro restaurant\n",
      "Loss: 0.4722578823566437\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5596 batches, and LR: 0.0005\n",
      "0 sauce chicken tomato onion potato mushroom fried grilled bean garlic\n",
      "1 dry overpriced worst top filet buck dollar average mediocre price\n",
      "2 pay dont didn money unless want wouldn doesn anything leave\n",
      "3 u minute asked table waiter manager min glass waitress water\n",
      "4 room wall space ceiling window lit floor lighting booth wood\n",
      "5 entree course portion fixe prix menu dish wine price bill\n",
      "6 went birthday saturday week night anniversary weekend friday month dined\n",
      "7 review year citysearch worst reviewer manager recently ever lived ve\n",
      "8 service staff waitstaff food attentive atmosphere rude hostess friendly prompt\n",
      "9 go reservation eat area wait get time sit ve waiting\n",
      "10 great excellent good amazing awesome delicious nice best perfect fantastic\n",
      "11 staff knowledgeable wood waitstaff gras tender tomato flavor professional helpful\n",
      "12 cream chocolate ice banana creme apple strawberry butter tea fruit\n",
      "13 cuisine fare american neighborhood authentic food indian mexican bistro restaurant\n",
      "Loss: 0.4484560191631317\n",
      "\n",
      "5596 batches, and LR: 0.0005\n",
      "0 sauce chicken tomato onion potato mushroom fried grilled bean garlic\n",
      "1 dry overpriced worst filet top buck dollar mediocre average price\n",
      "2 pay dont didn money unless want wouldn doesn anything leave\n",
      "3 u minute asked table waiter manager min glass waitress water\n",
      "4 room wall space ceiling window lit floor lighting booth wood\n",
      "5 entree course portion fixe prix menu dish wine bill price\n",
      "6 went birthday saturday week night anniversary weekend friday month dined\n",
      "7 review year citysearch worst reviewer manager recently ever lived owner\n",
      "8 service staff waitstaff food attentive atmosphere rude friendly prompt hostess\n",
      "9 go reservation eat area wait get time sit ve waiting\n",
      "10 great excellent good amazing awesome delicious nice best perfect fantastic\n",
      "11 staff wood knowledgeable waitstaff gras tender tomato flavor professional helpful\n",
      "12 cream chocolate ice banana creme apple strawberry butter tea fruit\n",
      "13 cuisine fare american neighborhood authentic indian food mexican bistro restaurant\n",
      "Loss: 0.543534517288208\n",
      "\n",
      "5596 batches, and LR: 0.0005\n",
      "0 sauce chicken tomato onion potato mushroom fried grilled bean garlic\n",
      "1 dry overpriced worst filet top buck dollar mediocre average price\n",
      "2 pay dont didn money unless want wouldn doesn anything leave\n",
      "3 u minute asked table waiter manager min waitress glass water\n",
      "4 room wall space ceiling window lit floor lighting booth wood\n",
      "5 entree course portion fixe prix menu dish wine bill price\n",
      "6 went birthday saturday week night anniversary weekend friday month dined\n",
      "7 review year citysearch worst reviewer manager recently ever owner lived\n",
      "8 service staff waitstaff food attentive atmosphere rude friendly prompt hostess\n",
      "9 go reservation eat area wait get time sit waiting ve\n",
      "10 great excellent good amazing awesome delicious nice best perfect fantastic\n",
      "11 staff wood knowledgeable waitstaff tender gras tomato flavor professional helpful\n",
      "12 cream chocolate ice banana creme apple strawberry butter tea fruit\n",
      "13 cuisine fare american neighborhood authentic indian mexican food bistro restaurant\n",
      "Loss: 0.48867878317832947\n",
      "\n",
      "5596 batches, and LR: 0.0005\n",
      "0 sauce chicken tomato onion potato mushroom fried grilled bean garlic\n",
      "1 dry overpriced worst filet top buck dollar mediocre average price\n",
      "2 pay dont didn money unless want wouldn doesn anything leave\n",
      "3 u minute asked table waiter manager min waitress glass water\n",
      "4 room wall space ceiling window lit floor lighting booth wood\n",
      "5 entree course portion fixe prix menu dish wine bill price\n",
      "6 went birthday saturday week night anniversary weekend friday month dined\n",
      "7 review year citysearch reviewer worst manager recently ever owner lived\n",
      "8 service staff waitstaff food attentive atmosphere rude friendly prompt hostess\n",
      "9 go reservation eat area wait get time sit waiting ve\n",
      "10 great excellent good amazing awesome delicious nice best perfect fantastic\n",
      "11 staff wood knowledgeable waitstaff tender gras flavor tomato professional helpful\n",
      "12 cream chocolate ice banana creme apple strawberry butter tea fruit\n",
      "13 cuisine fare american neighborhood authentic indian mexican food bistro restaurant\n",
      "Loss: 0.537055253982544\n",
      "\n",
      "5596 batches, and LR: 0.0005\n",
      "0 sauce chicken tomato onion potato mushroom fried grilled bean garlic\n",
      "1 dry overpriced filet worst top buck dollar mediocre average price\n",
      "2 pay dont didn money unless want wouldn doesn anything leave\n",
      "3 u minute asked table waiter manager min waitress glass water\n",
      "4 room wall space ceiling window lit floor lighting booth wood\n",
      "5 entree course portion fixe prix menu dish wine bill price\n",
      "6 went birthday saturday week night anniversary weekend friday month dined\n",
      "7 review year citysearch reviewer worst manager recently ever owner lived\n",
      "8 service staff waitstaff food attentive atmosphere rude friendly prompt hostess\n",
      "9 reservation go eat area wait get time sit waiting ve\n",
      "10 great excellent good amazing awesome delicious nice best perfect fantastic\n",
      "11 staff wood knowledgeable waitstaff tender gras flavor tomato professional helpful\n",
      "12 cream chocolate ice banana creme apple strawberry butter tea fruit\n",
      "13 cuisine fare american neighborhood authentic indian mexican food bistro restaurant\n",
      "Loss: 0.5422692894935608\n",
      "\n",
      "5596 batches, and LR: 0.0005\n",
      "0 sauce tomato chicken onion potato mushroom fried bean grilled garlic\n",
      "1 dry overpriced filet worst top buck dollar mediocre average price\n",
      "2 pay dont didn money unless want wouldn doesn anything leave\n",
      "3 u minute asked table waiter manager min waitress glass water\n",
      "4 room wall space ceiling window lit floor lighting booth wood\n",
      "5 entree course fixe portion prix menu dish wine bill price\n",
      "6 went birthday saturday week night anniversary weekend friday month dined\n",
      "7 review year citysearch reviewer manager worst recently ever owner chef\n",
      "8 service staff waitstaff food attentive atmosphere rude friendly prompt hostess\n",
      "9 reservation go eat area wait get time sit waiting ve\n",
      "10 great excellent good amazing awesome delicious nice best perfect fantastic\n",
      "11 wood staff knowledgeable waitstaff tender flavor gras tomato professional helpful\n",
      "12 cream chocolate ice banana creme apple strawberry butter tea fruit\n",
      "13 cuisine fare american neighborhood indian authentic mexican food bistro restaurant\n",
      "Loss: 0.38603320717811584\n",
      "\n",
      "5596 batches, and LR: 0.0005\n",
      "0 sauce tomato chicken onion potato mushroom fried bean grilled garlic\n",
      "1 dry overpriced filet worst top buck dollar mediocre average price\n",
      "2 pay dont didn money unless want wouldn doesn anything leave\n",
      "3 u minute asked table waiter manager min waitress glass water\n",
      "4 room wall space ceiling window lit floor lighting booth wood\n",
      "5 entree course fixe portion prix menu dish wine bill price\n",
      "6 went birthday saturday week night anniversary weekend friday month dined\n",
      "7 review year citysearch reviewer manager worst recently owner ever chef\n",
      "8 service staff waitstaff food attentive atmosphere rude friendly prompt hostess\n",
      "9 reservation eat go area wait get time sit waiting ve\n",
      "10 great excellent good amazing awesome delicious nice best perfect fantastic\n",
      "11 wood staff knowledgeable waitstaff tender flavor tomato gras professional helpful\n",
      "12 cream chocolate ice banana creme apple strawberry tea butter fruit\n",
      "13 cuisine fare american neighborhood indian mexican authentic food bistro restaurant\n",
      "Loss: 0.50420081615448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epoch_bar = tqdm(\n",
    "    desc='training routine', \n",
    "    total=args.epochs,\n",
    "    position=1,\n",
    ")\n",
    "\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm(\n",
    "    desc='train',\n",
    "    total=dataset.get_num_batches(args.batch_size), \n",
    "    position=1, \n",
    ")\n",
    "\n",
    "for epoch_index in range(args.epochs):\n",
    "    \n",
    "    train_state['epoch_index'] = epoch_index\n",
    "    \n",
    "    # Iterate over training dataset\n",
    "    # setup: batch generator, set loss to 0, set train mode on\n",
    "\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "\n",
    "    batch_generator = generate_batches(\n",
    "        dataset, \n",
    "        batch_size=args.batch_size, \n",
    "        device=args.device\n",
    "    )\n",
    "    \n",
    "    neg_batch_generator = generate_batches(\n",
    "        dataset, \n",
    "        batch_size=args.batch_size, \n",
    "        shuffle=False,\n",
    "        device=args.device,\n",
    "    )\n",
    "\n",
    "    for batch_index, batch_dict in enumerate(batch_generator):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x = batch_dict['x_data']\n",
    "        y = batch_dict['y_target'].float()\n",
    "        x_neg = next(neg_batch_generator)['x_data']\n",
    "\n",
    "        negative_samples = torch.stack(\n",
    "            tuple([x_neg[torch.randperm(x_neg.shape[0])[:args.neg_size]] \n",
    "                   for _ in range(args.batch_size)])\n",
    "        ).to(args.device)\n",
    "\n",
    "        anchor, positive, negative = model(x, negative_samples)\n",
    "        loss = loss_func(anchor, positive, negative)\n",
    "        loss_t = loss.item()\n",
    "\n",
    "        # compute the running loss\n",
    "        running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "        \n",
    "        # use loss to produce gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # use optimizer to take gradient step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # update bar\n",
    "        train_bar.set_postfix(loss=running_loss, epoch=epoch_index)\n",
    "        train_bar.update()\n",
    "\n",
    "    train_state['train_loss'].append(running_loss)\n",
    "    train_state = update_train_state(args=args, model=model, train_state=train_state)\n",
    "    scheduler.step(train_state['train_loss'][-1])\n",
    "    \n",
    "    print(batch_index, \"batches, and LR:\", optimizer.param_groups[0]['lr'])\n",
    "    for i, aspect in enumerate(model.get_aspect_words(w2v)):\n",
    "        print(i, \" \".join([a for a in aspect]))\n",
    "    print(\"Loss:\", loss.item())\n",
    "    print()\n",
    "\n",
    "    if train_state['stop_early']:\n",
    "        break\n",
    "\n",
    "    train_bar.n = 0\n",
    "\n",
    "    epoch_bar.set_postfix(best_val=train_state['early_stopping_best_val'])\n",
    "    epoch_bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "sns.lineplot(\n",
    "    x=[epoch + 1 for epoch in range(len(train_state['train_loss']))],\n",
    "    y=train_state['train_loss'],\n",
    "    color='coral', \n",
    "    label='loss',\n",
    ")\n",
    "\n",
    "plt.xticks([epoch for epoch in range(len(train_state['train_loss']) + 1)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(train_state['model_filename']))\n",
    "model = model.to(args.device)\n",
    "loss_func = torch.nn.MSELoss(reduction=\"sum\")\n",
    "dataset.set_split('test')\n",
    "\n",
    "batch_generator = generate_batches(\n",
    "    dataset, \n",
    "    batch_size=args.batch_size, \n",
    "    device=args.device,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "model.encoder_only = True\n",
    "predictions = []\n",
    "targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_index, batch_dict in enumerate(batch_generator):\n",
    "        \n",
    "        x = batch_dict['x_data']\n",
    "        y_target = batch_dict['y_target']\n",
    "        \n",
    "        y_pred = model(x, None)\n",
    "        for pred, target in zip(y_pred, y_target):\n",
    "            predictions.append(pred.cpu().numpy().argmax())\n",
    "            targets.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1490\n",
      "1490\n",
      "Counter({0: 704, 3: 270, 4: 209, 8: 103, 10: 61, 13: 38, 9: 28, 11: 18, 2: 17, 7: 15, 5: 15, 6: 12})\n",
      "Counter({'food': 887, 'staff': 352, 'ambience': 251})\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions))\n",
    "print(len(targets))\n",
    "print(Counter(predictions))\n",
    "print(Counter(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 sauce tomato chicken onion potato mushroom fried bean grilled garlic\n",
      "1 dry overpriced filet worst top buck dollar mediocre average price\n",
      "2 pay dont didn money unless want wouldn doesn anything leave\n",
      "3 u minute asked table waiter manager min waitress glass water\n",
      "4 room wall space ceiling window lit floor lighting booth wood\n",
      "5 entree course fixe portion prix menu dish wine bill price\n",
      "6 went birthday saturday week night anniversary weekend friday month dined\n",
      "7 review year citysearch reviewer manager worst recently owner ever chef\n",
      "8 service staff waitstaff food attentive atmosphere rude friendly prompt hostess\n",
      "9 reservation eat go area wait get time sit waiting ve\n",
      "10 great excellent good amazing awesome delicious nice best perfect fantastic\n",
      "11 wood staff knowledgeable waitstaff tender flavor tomato gras professional helpful\n",
      "12 cream chocolate ice banana creme apple strawberry tea butter fruit\n",
      "13 cuisine fare american neighborhood indian mexican authentic food bistro restaurant\n"
     ]
    }
   ],
   "source": [
    "for i, aspect in enumerate(model.get_aspect_words(w2v)):\n",
    "    print(i, \" \".join([a for a in aspect]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     ambience       0.85      0.71      0.77       251\n",
      "         food       0.90      0.86      0.88       887\n",
      "miscellaneous       0.00      0.00      0.00         0\n",
      "        staff       0.66      0.80      0.73       352\n",
      "\n",
      "     accuracy                           0.82      1490\n",
      "    macro avg       0.60      0.59      0.59      1490\n",
      " weighted avg       0.84      0.82      0.82      1490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cluster_map = {\n",
    "    0: 'food', \n",
    "    1: 'miscellaneous', \n",
    "    2: 'staff', \n",
    "    3: 'staff',\n",
    "    4: 'ambience', \n",
    "    5: 'food', \n",
    "    6: 'miscellaneous',  \n",
    "    7: 'staff', \n",
    "    8: 'staff', \n",
    "    9: 'food', \n",
    "    10: 'food', \n",
    "    11: 'staff', \n",
    "    12: 'miscellaneous', \n",
    "    13: 'food'\n",
    "}\n",
    "\n",
    "labels = ['ambience', 'food', 'miscellaneous', 'price', 'staff']\n",
    "\n",
    "y_pred = [cluster_map[pred] for pred in predictions]\n",
    "y_true = targets\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
