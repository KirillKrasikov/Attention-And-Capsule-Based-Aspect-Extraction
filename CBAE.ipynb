{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kkrasikov/PycharmProjects/TopicModelingWithCapsNet/venv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import codecs\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from tqdm.notebook import tqdm\n",
    "from argparse import Namespace\n",
    "from sklearn.cluster.k_means_ import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentences:\n",
    "    def __init__(self, filename: str):\n",
    "        self.filename = filename\n",
    "        self.num_lines = sum(1 for line in open(filename))\n",
    "\n",
    "    def __iter__(self):\n",
    "        for line in tqdm(\n",
    "            codecs.open(self.filename, \"r\", encoding=\"utf-8\"), \n",
    "            self.filename, \n",
    "            self.num_lines\n",
    "        ):\n",
    "            yield line.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_batches(path, batch_size=50, minlength=5):\n",
    "    \"\"\"\n",
    "        Reading batched texts of given min. length\n",
    "    :param path: path to the text file ``one line -- one normalized sentence''\n",
    "    :return: batches iterator\n",
    "    \"\"\"\n",
    "    batch = []\n",
    "\n",
    "    for line in open(path, encoding=\"utf-8\"):\n",
    "        line = line.strip().split()\n",
    "\n",
    "        # lines with less than `minlength` words are omitted\n",
    "        if len(line) >= minlength:\n",
    "            batch.append(line)\n",
    "            if len(batch) >= batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "\n",
    "    if len(batch) > 0:\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_batches(path, batch_size=50, minlength=5):\n",
    "    count = 0\n",
    "    batch_count = 0\n",
    "    \n",
    "    for line in open(path, encoding=\"utf-8\"):\n",
    "\n",
    "        if len(line) >= minlength:\n",
    "            batch_count += 1\n",
    "            if batch_count >= batch_size:\n",
    "                count += 1\n",
    "                batch_count = 0\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vectors(text, w2v_model, maxlen, vocabulary):\n",
    "    \"\"\"\n",
    "        Token sequence -- to a list of word vectors;\n",
    "        if token not in vocabulary, it is skipped; the rest of\n",
    "        the slots up to `maxlen` are replaced with zeroes\n",
    "    :param text: list of tokens\n",
    "    :param w2v_model: gensim w2v model\n",
    "    :param maxlen: max. length of the sentence; the rest is just cut away\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    acc_vecs = []\n",
    "\n",
    "    for word in text:\n",
    "        if word in w2v_model and (vocabulary is None or word in vocabulary):\n",
    "            acc_vecs.append(w2v_model.wv[word])\n",
    "\n",
    "    # padding for consistent length with ZERO vectors\n",
    "    if len(acc_vecs) < maxlen:\n",
    "        acc_vecs.extend([np.zeros(w2v_model.vector_size)] * (maxlen - len(acc_vecs)))\n",
    "\n",
    "    return acc_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_tensors(\n",
    "    path, \n",
    "    batch_size=50, \n",
    "    vocabulary=None,\n",
    "    maxlen=100, \n",
    "    pad_value=0, \n",
    "    minsentlength=5,\n",
    "    w2v_model=None,\n",
    "):\n",
    "    \"\"\"\n",
    "        Data for training the NN -- from text file to word vectors sequences batches\n",
    "    :param path:\n",
    "    :param batch_size:\n",
    "    :param vocabulary:\n",
    "    :param maxlen:\n",
    "    :param pad_value:\n",
    "    :param minsentlength:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for batch in read_data_batches(path, batch_size, minsentlength):\n",
    "        batch_vecs = []\n",
    "        batch_texts = []\n",
    "\n",
    "        for text in batch:\n",
    "            vectors_as_list = text2vectors(text, w2v_model, maxlen, vocabulary)\n",
    "            batch_vecs.append(np.asarray(vectors_as_list[:maxlen], dtype=np.float32))\n",
    "            batch_texts.append(text)\n",
    "\n",
    "        yield np.stack(batch_vecs, axis=0), batch_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroids(w2v_model, aspects_count):\n",
    "    \"\"\"\n",
    "        Clustering all word vectors with K-means and returning L2-normalizes\n",
    "        cluster centroids; used for ABAE aspects matrix initialization\n",
    "    \"\"\"\n",
    "\n",
    "    km = MiniBatchKMeans(n_clusters=aspects_count, verbose=0, n_init=100)\n",
    "    m = []\n",
    "\n",
    "    for k in w2v_model.wv.vocab:\n",
    "        m.append(w2v_model.wv[k])\n",
    "\n",
    "    m = np.matrix(m)\n",
    "\n",
    "    km.fit(m)\n",
    "    clusters = km.cluster_centers_\n",
    "\n",
    "    # L2 normalization\n",
    "    norm_aspect_matrix = clusters / np.linalg.norm(clusters, axis=-1, keepdims=True)\n",
    "\n",
    "    return norm_aspect_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels=200, out_channels=256, kernel_size=9, stride=1):\n",
    "        super(ConvLayer, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu(self.conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaryCaps(nn.Module):\n",
    "    def __init__(self, num_capsules=8, in_channels=256, out_channels=32, kernel_size=3):\n",
    "        super(PrimaryCaps, self).__init__()\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.capsules = nn.ModuleList([\n",
    "            nn.Conv1d(\n",
    "                in_channels=in_channels, \n",
    "                out_channels=out_channels, \n",
    "                kernel_size=kernel_size, \n",
    "                stride=2, \n",
    "                padding=0\n",
    "            ) \n",
    "            for _ in range(num_capsules)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        u = [capsule(x) for capsule in self.capsules]\n",
    "        u = torch.stack(u, dim=1)\n",
    "        u = u.view(x.size(0), 32 * 96 , -1)\n",
    "        return self.squash(u)\n",
    "    \n",
    "    def squash(self, input_tensor):\n",
    "        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n",
    "        output_tensor = squared_norm *  input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SecondaryCaps(nn.Module):\n",
    "    def __init__(self, num_capsules=10, num_routes=32 * 96, in_channels=8, out_channels=16):\n",
    "        super(SecondaryCaps, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.num_routes = num_routes\n",
    "        self.num_capsules = num_capsules\n",
    "        self.fc = nn.Linear(16 * 10, 1)\n",
    "\n",
    "        self.W = nn.Parameter(torch.randn(1, num_routes, num_capsules, out_channels, in_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = torch.stack([x] * self.num_capsules, dim=2).unsqueeze(4)\n",
    "\n",
    "        W = torch.cat([self.W] * batch_size, dim=0)\n",
    "        u_hat = torch.matmul(W, x)\n",
    "\n",
    "        b_ij = Variable(torch.zeros(1, self.num_routes, self.num_capsules, 1)).to(args.device)\n",
    "\n",
    "        num_iterations = 3\n",
    "        for iteration in range(num_iterations):\n",
    "            c_ij = F.softmax(b_ij)\n",
    "            c_ij = torch.cat([c_ij] * batch_size, dim=0).unsqueeze(4)\n",
    "\n",
    "            s_j = (c_ij * u_hat).sum(dim=1, keepdim=True)\n",
    "            v_j = self.squash(s_j)\n",
    "            \n",
    "            if iteration < num_iterations - 1:\n",
    "                a_ij = torch.matmul(u_hat.transpose(3, 4), torch.cat([v_j] * self.num_routes, dim=1))\n",
    "                b_ij = b_ij + a_ij.squeeze(4).mean(dim=0, keepdim=True)\n",
    "\n",
    "        return v_j.squeeze(1)\n",
    "    \n",
    "    def squash(self, input_tensor):\n",
    "        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n",
    "        output_tensor = squared_norm *  input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CapsNet, self).__init__()\n",
    "        self.conv_layer = ConvLayer()\n",
    "        self.primary_caps = PrimaryCaps()\n",
    "        self.secondary_caps = SecondaryCaps()\n",
    "        \n",
    "        self.fc = nn.Linear(16 * 10, 201)\n",
    "\n",
    "    def forward(self, data):\n",
    "        output = self.secondary_caps(self.primary_caps(self.conv_layer(data)))\n",
    "        output = output.reshape(50, 160)\n",
    "\n",
    "        return self.fc(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBAE(torch.nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        wv_dim: int = 200, \n",
    "        asp_count: int = 30,\n",
    "        ortho_reg: float = 0.1, \n",
    "        maxlen: int = 201, \n",
    "        init_aspects_matrix=None\n",
    "    ):\n",
    "        super(CBAE, self).__init__()\n",
    "        self.wv_dim = wv_dim\n",
    "        self.asp_count = asp_count\n",
    "        self.ortho = ortho_reg\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "        self.caps_net = CapsNet()\n",
    "        self.linear_transform = torch.nn.Linear(self.wv_dim, self.asp_count)\n",
    "        self.softmax_aspects = torch.nn.Softmax()\n",
    "        self.aspects_embeddings = Parameter(torch.empty(size=(wv_dim, asp_count)))\n",
    "\n",
    "        if init_aspects_matrix is None:\n",
    "            torch.nn.init.xavier_uniform(self.aspects_embeddings)\n",
    "        else:\n",
    "            self.aspects_embeddings.data = torch.from_numpy(init_aspects_matrix.T)\n",
    "\n",
    "    def get_aspects_importances(self, text_embeddings):\n",
    "        \"\"\"Takes embeddings of a sentence as input, returns attention weights\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # compute attention scores, looking at text embeddings average\n",
    "        caps_weights = self.caps_net(text_embeddings.permute(0, 2, 1))\n",
    "\n",
    "        # multiplying text embeddings by attention scores -- and summing\n",
    "        # (matmul: we sum every word embedding's coordinate with attention weights)\n",
    "        weighted_text_emb = torch.matmul(caps_weights.unsqueeze(1),  # (batch, 1, sentence)\n",
    "                                         text_embeddings  # (batch, sentence, wv_dim)\n",
    "                                         ).squeeze()\n",
    "\n",
    "        # encoding with a simple feed-forward layer (wv_dim) -> (aspects_count)\n",
    "        raw_importances = self.linear_transform(weighted_text_emb)\n",
    "\n",
    "        # computing 'aspects distribution in a sentence'\n",
    "        aspects_importances = self.softmax_aspects(raw_importances)\n",
    "\n",
    "        return caps_weights, aspects_importances, weighted_text_emb\n",
    "\n",
    "    def forward(self, text_embeddings, negative_samples_texts):\n",
    "\n",
    "        # negative samples are averaged\n",
    "        averaged_negative_samples = torch.mean(negative_samples_texts, dim=2)\n",
    "        \n",
    "        # encoding: words embeddings -> sentence embedding, aspects importances\n",
    "        _, aspects_importances, weighted_text_emb = self.get_aspects_importances(text_embeddings)\n",
    "\n",
    "        # decoding: aspects embeddings matrix, aspects_importances -> recovered sentence embedding\n",
    "        recovered_emb = torch.matmul(self.aspects_embeddings, aspects_importances.unsqueeze(2)).squeeze()\n",
    "\n",
    "        # loss\n",
    "        reconstruction_triplet_loss = CBAE._reconstruction_loss(\n",
    "            weighted_text_emb,\n",
    "            recovered_emb,\n",
    "            averaged_negative_samples,\n",
    "        )\n",
    "        \n",
    "        max_margin = torch.max(reconstruction_triplet_loss, torch.zeros_like(reconstruction_triplet_loss))\n",
    "        reconstruction_triplet_loss\n",
    "\n",
    "        return self.ortho * self._ortho_regularizer() + max_margin\n",
    "\n",
    "    @staticmethod\n",
    "    def _reconstruction_loss(text_emb, recovered_emb, averaged_negative_emb):\n",
    "\n",
    "        positive_dot_products = torch.matmul(text_emb.unsqueeze(1), recovered_emb.unsqueeze(2)).squeeze()\n",
    "        negative_dot_products = torch.matmul(averaged_negative_emb, recovered_emb.unsqueeze(2)).squeeze()\n",
    "        reconstruction_triplet_loss = torch.sum(1 - positive_dot_products.unsqueeze(1) + negative_dot_products, dim=1)\n",
    "\n",
    "        return reconstruction_triplet_loss\n",
    "\n",
    "    def _ortho_regularizer(self):\n",
    "        return torch.norm(\n",
    "            torch.matmul(self.aspects_embeddings.t(), self.aspects_embeddings) \\\n",
    "            - torch.eye(self.asp_count).to(args.device))\n",
    "\n",
    "    def get_aspect_words(self, w2v_model, topn=15):\n",
    "        words = []\n",
    "\n",
    "        # getting aspects embeddings\n",
    "        aspects = self.aspects_embeddings.cpu().detach().numpy()\n",
    "\n",
    "        # getting scalar products of word embeddings and aspect embeddings;\n",
    "        # to obtain the ``probabilities'', one should also apply softmax\n",
    "        words_scores = w2v_model.wv.syn0.dot(aspects)\n",
    "\n",
    "        for row in range(aspects.shape[1]):\n",
    "            argmax_scalar_products = np.argsort(- words_scores[:, row])[:topn]\n",
    "            # print([w2v_model.wv.index2word[i] for i in argmax_scalar_products])\n",
    "            # print([w for w, dist in w2v_model.similar_by_vector(aspects.T[row])[:topn]])\n",
    "            words.append([w2v_model.wv.index2word[i] for i in argmax_scalar_products])\n",
    "\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    data_json='Electronics_5.json',\n",
    "    \n",
    "    w2v_file='Electronics_5.w2v',\n",
    "    w2v_size=200,\n",
    "    w2v_window=5,\n",
    "    w2v_min_count=5,\n",
    "    w2v_workers=7,\n",
    "    w2v_sg=1,\n",
    "    w2v_negative=5,\n",
    "    w2v_iter=1,\n",
    "    w2v_max_vocab_size=20000,\n",
    "    \n",
    "    batch_size=50,\n",
    "    aspects_number=40,\n",
    "    ortho_reg=0.1,\n",
    "    epochs=1,\n",
    "    optimizer='adam',\n",
    "    neg_samples=5,\n",
    "    maxlen=201,\n",
    "    \n",
    "    cuda=True,\n",
    "    reload_from_files=True,\n",
    ")\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "    \n",
    "print(\"Using CUDA: {}\".format(args.cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vectorizer\n"
     ]
    }
   ],
   "source": [
    "if args.reload_from_files:\n",
    "    print(\"Loading vectorizer\")\n",
    "    pass\n",
    "else:\n",
    "    print(\"Loading dataset and creating vectorizer\")\n",
    "    sentences = Sentences(args.data_json)\n",
    "    w2v = gensim.models.Word2Vec(\n",
    "        sentences, \n",
    "        size=args.w2v_size, \n",
    "        window=args.w2v_window, \n",
    "        min_count=args.w2v_min_count, \n",
    "        workers=args.w2v_workers, \n",
    "        sg=args.w2v_sg,\n",
    "        negative=args.w2v_negative, \n",
    "        iter=args.w2v_iter, \n",
    "        max_vocab_size=args.w2v_max_vocab_size,\n",
    "    )\n",
    "    w2v.save(args.w2v_file)\n",
    "    print(f'{args.w2v_file} saved')\n",
    "    \n",
    "vectorizer = gensim.models.Word2Vec.load(args.w2v_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he ['she', 'He', 'his', 'She', 'son', 'husband', 'him', 'dad', 'daughter', 'wife']\n",
      "love ['LOVE', 'Love', 'loved', '\"Love', 'enjoy', 'hate', 'loves', 'appreciate', 'enjoyed', 'like']\n",
      "looks ['feels', 'Looks', 'look', 'looked', 'sleek', 'sounds', 'matches', 'finish', 'appearance', 'look.']\n",
      "buy ['purchase', 'buying', 'purchasing', 'sell', 'ordering', 'buy,', 'invest', 'try', 'buy.', 'order']\n",
      "laptop ['notebook', 'netbook', 'computer', 'laptop,', 'machine', 'laptop.', 'PC', 'desktop', 'tablet', 'pc']\n"
     ]
    }
   ],
   "source": [
    "for word in [\"he\", \"love\", \"looks\", \"buy\", \"laptop\"]:\n",
    "    if word in vectorizer.wv.vocab:\n",
    "        print(word, [w for w, c in vectorizer.wv.similar_by_word(word=word)])\n",
    "    else:\n",
    "        print(word, \"not in vocab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_dim = vectorizer.vector_size\n",
    "y = torch.zeros(args.batch_size, 1).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CBAE(\n",
       "  (caps_net): CapsNet(\n",
       "    (conv_layer): ConvLayer(\n",
       "      (conv): Conv1d(200, 256, kernel_size=(9,), stride=(1,))\n",
       "    )\n",
       "    (primary_caps): PrimaryCaps(\n",
       "      (capsules): ModuleList(\n",
       "        (0): Conv1d(256, 32, kernel_size=(3,), stride=(2,))\n",
       "        (1): Conv1d(256, 32, kernel_size=(3,), stride=(2,))\n",
       "        (2): Conv1d(256, 32, kernel_size=(3,), stride=(2,))\n",
       "        (3): Conv1d(256, 32, kernel_size=(3,), stride=(2,))\n",
       "        (4): Conv1d(256, 32, kernel_size=(3,), stride=(2,))\n",
       "        (5): Conv1d(256, 32, kernel_size=(3,), stride=(2,))\n",
       "        (6): Conv1d(256, 32, kernel_size=(3,), stride=(2,))\n",
       "        (7): Conv1d(256, 32, kernel_size=(3,), stride=(2,))\n",
       "      )\n",
       "    )\n",
       "    (secondary_caps): SecondaryCaps(\n",
       "      (fc): Linear(in_features=160, out_features=1, bias=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=160, out_features=201, bias=True)\n",
       "  )\n",
       "  (linear_transform): Linear(in_features=200, out_features=40, bias=True)\n",
       "  (softmax_aspects): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CBAE(\n",
    "    wv_dim=wv_dim,\n",
    "    asp_count=args.aspects_number,\n",
    "    init_aspects_matrix=get_centroids(vectorizer, aspects_count=args.aspects_number)\n",
    ")\n",
    "model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c886bf59ebf4311af11c68dd14b5cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='training routine', max=1.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2dc11038d2477a865cb560c8782920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='train', max=33782.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-9765a737981f>:15: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if word in w2v_model and (vocabulary is None or word in vocabulary):\n",
      "<ipython-input-10-764fc908406b>:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  c_ij = F.softmax(b_ij)\n",
      "<ipython-input-12-308166b19553>:45: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  aspects_importances = self.softmax_aspects(raw_importances)\n",
      "/home/kkrasikov/PycharmProjects/TopicModelingWithCapsNet/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:432: UserWarning: Using a target size (torch.Size([50, 1])) that is different to the input size (torch.Size([50])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 batches, and LR: 0.001\n",
      "1 photography, portraits photography outdoors photography. trips situations photographer indoors amateur studio school yard casual gym\n",
      "2 thousands kinds sorts sites variety countless various hundreds types books, (including numerous etc.) options, formats\n",
      "3 Player Desktop GB Drive Music Portable Network Adobe downloaded Office Google Adapter Seagate Wireless Vista\n",
      "4 for.\", future.\", again.\", anyone.\", to.\", time.\", these.\", needs.\", with.\", in.\", one.\", years.\", do.\", around.\", fine.\",\n",
      "5 appearance sleek aluminum feel, stylish leather elegant protects gray weight, color, padding matches bulk attractive\n",
      "6 \"Kenneth \"Jonathan \"Bruce \"William \"Kevin \"Stephen \"Peter \"Thomas \"Richard \"Scott \"Jerry \"N. \"Eric \"Robert \"Daniel\n",
      "7 birthday ago Christmas contacted died \"I've \"Bought sister \"B003ES5ZUU\", ago, \"Bruce daughter \"Purchased weeks week\n",
      "8 select restart press unplug delete enter icon reset activate manually turn pressing click automatically button,\n",
      "9 highs mids treble lows bass bass, bass. midrange muddy tinny classical hiss Bass distortion distortion.\n",
      "10 price\", price.\", price!\", money\", price. money.\", money. price, money, Price\", cost. price cost, money value.\",\n",
      "11 price\", money\", camera\", case\", lens\", quality\", sound\", cable\", value\", product\", speakers\", bag\", player\", headphones\", 2012\"}\n",
      "12 Price\", Cable\", Quality\", Value\", Adapter Value Portable Kit Speaker Cable Headphones Case Product\", Card Stereo\n",
      "13 should\", \"B003ES5ZUU\", \"B003ELYQGG\", \"Jerry \"B002V88HFE\", \"Bruce \"B002WE6D44\", says, \"N. \"B0019EHU8G\", \"Thomas \"Kenneth \"Jonathan Miller\", \"Daniel\n",
      "14 brands chargers bags pieces remotes protectors mice sizes pockets lenses keyboards headsets adapters buds cases\n",
      "15 producing providing creating picking losing hitting developed becoming pressing offering dropping causing entering adding turning\n",
      "16 amplifier bookshelf player, subwoofer receiver 5.1 router, stereo, stereo players, RCA speakers, TV, network, surround\n",
      "17 advise comment talked complained wondering told complaining advice questions knows suggestion bothered agree convinced decide\n",
      "18 headband cups cushions pads earpieces ear foam ears ears. ear. padding ear, head. ears, comfortable.\n",
      "19 TO WAS HAVE MY WITH FOR OF AS THE YOU BE ARE IN YOUR ON\n",
      "20 [13, [11, [14, [9, [10, [15, [16, [12, [17, [8, [19, [7, [20, [18, 17],\n",
      "21 outlet. hub. modem. router. receiver. plug. connector. speaker. port. antenna. network. stereo. cable. speakers. cord.\n",
      "22 fact, addition, Personally, it.The whereas example, \"B003ES5ZUU\", Finally, Also, (you mode, Therefore, Still, However, course,\n",
      "23 flap bend tighten sliding folded slip slide folds fold rubber velcro sides friction edges cups\n",
      "24 inches width diameter feet. 1/4\\\" feet wider mm angle focal x ft tall wide distance\n",
      "25 travel traveling travel. carry trips purse companion carrying backpack bag\", bag.\", gym trip walking bag\n",
      "26 problems.\", problems\", problems issues problem.\", issues. problems. problems, questions issues, complaints trouble difficulty complaints. problem\n",
      "27 amazed impressed surprised pleased shocked pleasantly excited thrilled disappointed skeptical satisfied hesitant happy frustrated happier\n",
      "28 Stars\", \"Amazon 2010\"} \"Five Price\", \"very \"works \"nice \"Tom 2009\"} \"good \"Kenneth \"Fits \"My \"These\n",
      "29 portable, portable. compact, intuitive loud, lightweight, convenient versatile comfortable, attractive pleasing powerful responsive lightweight small,\n",
      "30 there's There's \"There \"There's there There adds leaves audiophile, you'll you're it'll it's offers you've\n",
      "31 f/2.8 18-55mm EF 70-200 telephoto Nikkor focal 50mm 70-200mm 35mm lenses lens. Tamron aperture lens,\n",
      "32 yard apartment chair bed basement floor house, kitchen room, upstairs rooms garage bedroom sitting desk,\n",
      "33 SDHC PCI CF GB SD Card cards card card. cards. 64 cards, slot, card, reader\n",
      "34 since. with. try. owned. hour. together. mode. other. past. bit. through. available. stores. soon. beat.\n",
      "35 Work Easy Read Works Used Will Tried Worked \"B003ELYQGG\", \"B003ES5ZUU\", Have Plug Make \"W. Did\n",
      "36 password browser DHCP CD. download downloaded network, drivers. downloading XP updates networks Vista drivers file\n",
      "37 ear. pocket, pocket. purse ear, ears. ears, shirt pockets compartment pocket ears shoulder hands. hand.\n",
      "38 extremely exceptionally incredibly fairly amazingly surprisingly relatively very very, equally ridiculously VERY pretty reasonably super\n",
      "39 12], 11], 13], 10], 16], 15], 14], 17], 9], 19], 18], 8], 20], 22], [11,\n",
      "40 3.5mm port, RCA Ethernet ethernet coaxial DVI port jacks jack VGA male port. outlet HDMI\n",
      "Loss: 240829.140625\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-308166b19553>:94: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  words_scores = w2v_model.wv.syn0.dot(aspects)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 batches, and LR: 0.001\n",
      "1 photography, photography photography. amateur photographer portraits studio casual outdoors school editing everyday situations daily outdoor\n",
      "2 variety countless thousands tons numerous bunch hundreds various kinds many sorts ton types lots several\n",
      "3 movies Music TiVo Google Player Portable games videos DVDs Tivo Desktop DVD's books Seagate HD\n",
      "4 future.\", to.\", again.\", for.\", on.\", in.\", fine.\", one.\", these.\", time.\", stars.\", me.\", now.\", that.\", them.\",\n",
      "5 sleek appearance color, bulk color. color matches slim elegant protects gray stylish leather protection feel,\n",
      "6 \"William \"Richard \"Robert \"Bruce \"Kevin \"Scott \"Mike \"Thomas \"Brian \"Paul \"N. \"Peter \"Kenneth \"John \"Stephen\n",
      "7 birthday Christmas lasted died sister contacted ago gift weeks week daughter month sent months dad\n",
      "8 select press turn restart unplug adjust seconds delete activate change reset manually enter click skip\n",
      "9 highs mids treble lows bass bass, bass. muddy midrange tinny classical Bass hiss distortion distortion.\n",
      "10 price\", price.\", price!\", money\", money.\", price. money, price, money. cost. money price Price\", cost, bang\n",
      "11 sound\", lens\", money\", value\", product\", cable\", price\", headphones\", camera\", case\", quality\", speakers\", bag\", player\", item\",\n",
      "12 Price\", Cable\", Quality\", Value Adapter Value\", Headphones Case Speaker Kit Portable Cable System Cables Camera\n",
      "13 should\", says, advertised.\", says described advertised\", description advertised advertised, states supposed described. stated expected\", title\n",
      "14 remotes protectors brands bags chargers items mice cases pieces adapters keyboards gadgets headsets accessories radios\n",
      "15 providing losing producing becoming dropping adding creating picking offering giving sending entering hitting developed changing\n",
      "16 headset, bookshelf receiver 5.1 speakers, mouse, subwoofer speaker player, speaker, 7.1 radio, TV, system, surround\n",
      "17 advise comment knows advice please complained comments complain questions suggest suggestion recomend understand complaining talked\n",
      "18 headband cups cushions pads earpieces foam ear uncomfortable ears comfortable. wear. head. bud ears. head\n",
      "19 TO HAVE MY WITH WAS FOR OF AS THE YOU ARE BE YOUR ON IN\n",
      "20 [8, [7, [9, [10, [13, [6, [12, [11, [14, [16, [17, [5, [15, [4, [18,\n",
      "21 router. modem. hub. mouse. keyboard. receiver. charger. headset. speaker. outlet. cable. cord. remote. connector. radio.\n",
      "22 Personally, Still, Either While Since However, Sometimes Needless reason, Although Unfortunately, Therefore, Unless Also, Considering\n",
      "23 tighten bend adhesive slide sliding flap slip plastic lay stiff wipe edges rubber scratched tape\n",
      "24 inches feet. width feet ft wider diameter x extends foot 1/4 tall 25 angle mm\n",
      "25 travel traveling travel. carry companion trips carrying purse everywhere needed.\", portable trip portability everyday backpack\n",
      "26 problems.\", problems\", problems issues problem.\", issues. problems. problems, issues, trouble complaints difficulty questions complaints. problem\n",
      "27 impressed amazed pleased surprised pleasantly thrilled disappointed shocked satisfied happy excited skeptical happier frustrated blown\n",
      "28 \"it \"works \"great \"nice \"good \"very \"My \"If \"not \"Fits \"Works \"Nice \"the \"Good \"Worked\n",
      "29 convenient portable, powerful intuitive useful, versatile compact, annoying, portable. useful loud, responsive handy small, useful.\n",
      "30 there's \"There \"There's There's there There you'll you're leaves it'll it's adds audiophile, offers 2011\"}\n",
      "31 f/2.8 EF 70-200 70-200mm 18-55mm 50mm Nikkor telephoto VR Tamron lens. USM 35mm focal lenses\n",
      "32 basement yard apartment floor kitchen bed bedroom room, rooms chair upstairs garage house, living sitting\n",
      "33 SDHC PCI CF cards card cards, cards. SD card. card, Card memory 64 reader GB\n",
      "34 owned. available. apart. free. another. anywhere. soon. through. since. over. try. wear. included. down. with.\n",
      "35 Easy Did Will Does Have Make Works Much Used Looks Didn't Never Haven't Worked Comes\n",
      "36 password browser DHCP drivers updates XP IP Vista downloaded download CD. drivers. software downloading Windows\n",
      "37 pocket. pocket, ear. purse pocket shirt ear, ears. pockets ears, bag.\", comfortably shoulder hands. ears\n",
      "38 extremely incredibly exceptionally fairly amazingly relatively very surprisingly equally VERY ridiculously pretty super quite very,\n",
      "39 11], 12], 13], 10], 14], 15], 9], 16], 17], 18], 8], 19], 20], 7], 22],\n",
      "40 3.5mm RCA coaxial DVI port, male VGA ethernet port jacks DC Ethernet jack port. plugs\n",
      "Loss: 2.397942066192627\n",
      "\n",
      "2000 batches, and LR: 0.001\n",
      "1 photography, photography photography. amateur photographer portraits studio casual outdoors school editing everyday situations daily outdoor\n",
      "2 variety countless thousands tons numerous bunch hundreds various many kinds sorts ton types lots several\n",
      "3 movies Music TiVo Google Player Portable games videos Tivo DVDs Desktop DVD's books Seagate HD\n",
      "4 future.\", to.\", again.\", for.\", on.\", in.\", fine.\", one.\", these.\", time.\", stars.\", me.\", now.\", that.\", them.\",\n",
      "5 sleek appearance color, bulk color. color matches slim elegant protects gray stylish leather protection feel,\n",
      "6 \"William \"Richard \"Robert \"Bruce \"Kevin \"Scott \"Mike \"Brian \"Thomas \"Paul \"N. \"Peter \"John \"Stephen \"Kenneth\n",
      "7 birthday Christmas lasted died sister ago contacted gift weeks week daughter month sent months dad\n",
      "8 select press turn restart unplug adjust seconds activate delete change reset manually enter skip click\n",
      "9 highs mids treble lows bass bass, bass. muddy midrange tinny classical Bass hiss distortion distortion.\n",
      "10 price\", price.\", price!\", money\", money.\", price. money, price, money. cost. money price cost, Price\", bang\n",
      "11 sound\", lens\", money\", value\", product\", cable\", price\", headphones\", camera\", case\", quality\", speakers\", bag\", player\", item\",\n",
      "12 Price\", Cable\", Quality\", Value Adapter Value\", Headphones Case Speaker Kit Cable System Portable Cables Camera\n",
      "13 should\", says, advertised.\", says described advertised\", description advertised advertised, supposed states described. stated expected\", title\n",
      "14 remotes protectors brands bags chargers items mice cases pieces adapters gadgets keyboards headsets accessories radios\n",
      "15 providing losing producing becoming dropping adding creating picking offering giving sending entering hitting developed changing\n",
      "16 headset, bookshelf receiver 5.1 speakers, mouse, subwoofer speaker speaker, player, 7.1 radio, system, TV, surround\n",
      "17 advise comment knows advice please complained complain comments suggest questions suggestion recomend understand complaining talked\n",
      "18 headband cups cushions pads earpieces foam ear uncomfortable ears comfortable. wear. bud head. ears. head\n",
      "19 TO HAVE MY WITH WAS FOR OF AS THE YOU ARE BE YOUR ON IN\n",
      "20 [8, [7, [9, [10, [13, [6, [12, [11, [14, [16, [17, [5, [15, [4, [18,\n",
      "21 router. modem. hub. mouse. keyboard. receiver. charger. headset. speaker. outlet. cable. cord. radio. remote. connector.\n",
      "22 Personally, Still, Either While Since However, Needless Sometimes reason, Although Unfortunately, Therefore, Unless Considering Also,\n",
      "23 tighten bend adhesive slide sliding flap slip plastic lay stiff wipe edges scratched rubber tape\n",
      "24 inches feet. width feet ft wider diameter x extends foot 1/4 tall 25 mm 45\n",
      "25 travel traveling travel. carry companion trips carrying purse everywhere needed.\", portable trip portability everyday backpack\n",
      "26 problems.\", problems\", problems issues problem.\", issues. problems. problems, issues, trouble complaints difficulty questions complaints. problem\n",
      "27 impressed amazed pleased surprised pleasantly thrilled disappointed shocked satisfied happy excited happier skeptical frustrated blown\n",
      "28 \"it \"works \"great \"nice \"good \"very \"My \"If \"not \"Works \"Nice \"Fits \"the \"Good \"It\n",
      "29 convenient portable, powerful intuitive useful, versatile compact, annoying, portable. useful loud, responsive handy small, frustrating\n",
      "30 there's \"There \"There's There's there There you'll you're leaves it'll it's adds audiophile, offers that's\n",
      "31 f/2.8 EF 70-200 70-200mm 18-55mm 50mm Nikkor telephoto VR Tamron lens. USM 35mm focal lenses\n",
      "32 basement yard apartment floor kitchen bed bedroom room, rooms chair garage upstairs house, living sitting\n",
      "33 SDHC PCI CF cards card cards, cards. SD card. card, Card memory 64 reader GB\n",
      "34 owned. apart. available. free. another. soon. anywhere. since. over. through. try. wear. down. included. with.\n",
      "35 Easy Did Will Does Have Much Works Make Used Looks Didn't Never Haven't Lots Worked\n",
      "36 password browser DHCP drivers updates XP IP Vista downloaded download CD. drivers. software downloading Windows\n",
      "37 pocket. pocket, ear. purse pocket shirt ear, ears. pockets ears, bag.\", comfortably shoulder ears hands.\n",
      "38 extremely incredibly exceptionally fairly amazingly relatively very surprisingly equally VERY ridiculously pretty super quite very,\n",
      "39 11], 12], 13], 10], 14], 15], 9], 16], 17], 18], 8], 19], 20], 7], 22],\n",
      "40 3.5mm RCA coaxial DVI port, male VGA ethernet port jacks DC Ethernet jack port. HDMI\n",
      "Loss: 0.00447921734303236\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 batches, and LR: 0.001\n",
      "1 photography, photography photography. amateur photographer portraits studio casual outdoors school editing everyday situations daily outdoor\n",
      "2 variety countless thousands tons numerous bunch hundreds various many kinds sorts ton types lots several\n",
      "3 movies Music TiVo Google Player Portable games videos DVDs Tivo Desktop books DVD's Seagate HD\n",
      "4 future.\", to.\", again.\", for.\", on.\", in.\", fine.\", one.\", these.\", time.\", stars.\", me.\", now.\", that.\", them.\",\n",
      "5 sleek appearance color, bulk color. color matches slim elegant protects gray stylish leather protection feel,\n",
      "6 \"William \"Richard \"Robert \"Bruce \"Kevin \"Scott \"Mike \"Brian \"Thomas \"Paul \"N. \"Peter \"John \"Stephen \"Daniel\n",
      "7 birthday Christmas lasted died sister ago contacted gift weeks week daughter month sent months dad\n",
      "8 select press turn restart unplug adjust seconds activate delete change reset manually enter skip click\n",
      "9 highs mids treble lows bass bass, bass. muddy midrange tinny classical Bass hiss distortion distortion.\n",
      "10 price\", price.\", price!\", money\", money.\", price. money, price, money. cost. money price cost, Price\", bang\n",
      "11 sound\", lens\", money\", value\", product\", cable\", price\", headphones\", camera\", case\", quality\", speakers\", bag\", player\", item\",\n",
      "12 Price\", Cable\", Quality\", Value Adapter Value\", Headphones Case Speaker Kit Cable System Portable Cables Camera\n",
      "13 should\", says, advertised.\", says described advertised\", description advertised advertised, supposed states described. stated expected\", title\n",
      "14 remotes protectors brands bags chargers items mice cases pieces adapters gadgets keyboards headsets accessories radios\n",
      "15 providing losing producing becoming dropping adding creating picking offering giving sending entering hitting developed changing\n",
      "16 headset, bookshelf receiver 5.1 speakers, mouse, subwoofer speaker speaker, player, 7.1 radio, system, TV, surround\n",
      "17 advise comment knows advice please complained complain comments suggest questions suggestion recomend understand complaining talked\n",
      "18 headband cups cushions pads earpieces foam ear uncomfortable ears comfortable. wear. bud head. ears. head\n",
      "19 TO HAVE MY WITH WAS FOR OF AS THE YOU ARE BE YOUR ON IN\n",
      "20 [8, [7, [9, [10, [13, [6, [12, [11, [14, [16, [17, [5, [15, [4, [18,\n",
      "21 router. modem. hub. mouse. keyboard. receiver. charger. headset. speaker. outlet. cable. cord. radio. remote. connector.\n",
      "22 Personally, Still, Either While Since However, Needless Sometimes reason, Although Unfortunately, Therefore, Unless Considering Also,\n",
      "23 tighten bend adhesive slide sliding flap slip plastic lay stiff wipe edges scratched rubber tape\n",
      "24 inches feet. width feet ft wider diameter x extends foot 1/4 tall 25 45 mm\n",
      "25 travel traveling travel. carry companion trips carrying purse everywhere needed.\", portable trip portability everyday backpack\n",
      "26 problems.\", problems\", problems issues problem.\", issues. problems. problems, issues, trouble complaints difficulty questions complaints. problem\n",
      "27 impressed amazed pleased surprised pleasantly thrilled disappointed shocked satisfied happy excited happier skeptical frustrated blown\n",
      "28 \"it \"works \"great \"nice \"good \"very \"My \"If \"not \"Works \"Nice \"Fits \"the \"Good \"Worked\n",
      "29 convenient portable, powerful intuitive useful, versatile compact, annoying, portable. useful loud, responsive handy small, frustrating\n",
      "30 there's \"There \"There's There's there There you'll you're leaves it'll it's adds audiophile, offers that's\n",
      "31 f/2.8 EF 70-200 70-200mm 18-55mm 50mm Nikkor telephoto VR Tamron lens. USM 35mm focal lenses\n",
      "32 basement yard apartment floor kitchen bed bedroom room, rooms chair garage upstairs house, living sitting\n",
      "33 SDHC PCI CF cards card cards, cards. SD card. card, Card memory 64 reader GB\n",
      "34 owned. apart. available. free. another. soon. anywhere. since. over. through. try. wear. down. included. with.\n",
      "35 Easy Will Did Does Have Much Works Make Used Looks Didn't Never Haven't Lots Worked\n",
      "36 password browser DHCP drivers updates XP IP Vista downloaded download CD. drivers. software downloading Win\n",
      "37 pocket. pocket, ear. purse pocket shirt ear, ears. pockets ears, bag.\", comfortably shoulder ears hands.\n",
      "38 extremely incredibly exceptionally fairly amazingly relatively very surprisingly equally VERY ridiculously pretty super quite very,\n",
      "39 11], 12], 13], 10], 14], 15], 9], 16], 17], 18], 8], 19], 20], 7], 22],\n",
      "40 3.5mm RCA coaxial DVI port, male VGA ethernet port DC jacks Ethernet jack port. HDMI\n",
      "Loss: 2.280175976920873e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epoch_bar = tqdm(\n",
    "    desc='training routine', \n",
    "    total=args.epochs,\n",
    "    position=0\n",
    ")\n",
    "\n",
    "train_bar = tqdm(\n",
    "    desc='train',\n",
    "    total=get_num_batches(args.data_json, args.batch_size, args.maxlen), \n",
    "    position=1, \n",
    "    leave=True\n",
    ")\n",
    "\n",
    "\n",
    "for t in range(args.epochs):\n",
    "\n",
    "    print(\"Epoch %d/%d\" % (t + 1, args.epochs))\n",
    "\n",
    "    data_iterator = read_data_tensors(\n",
    "        args.data_json,\n",
    "        batch_size=args.batch_size, \n",
    "        maxlen=args.maxlen,\n",
    "        w2v_model=vectorizer,\n",
    "    )\n",
    "\n",
    "    for item_number, (x, texts) in enumerate(data_iterator):\n",
    "        if x.shape[0] < args.batch_size:  # pad with 0 if smaller than batch size\n",
    "            x = np.pad(x, ((0, args.batch_size - x.shape[0]), (0, 0), (0, 0)))\n",
    "\n",
    "        x = torch.from_numpy(x).to(args.device)\n",
    "\n",
    "        # extracting bad samples from the very same batch; not sure if this is OK, so todo\n",
    "        negative_samples = torch.stack(\n",
    "            tuple([x[torch.randperm(x.shape[0])[:args.neg_samples]] \n",
    "                   for _ in range(args.batch_size)])\n",
    "        ).to(args.device)\n",
    "\n",
    "        # prediction\n",
    "        y_pred = model(x, negative_samples)\n",
    "\n",
    "        # error computation\n",
    "        loss = criterion(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if item_number % 1000 == 0:\n",
    "\n",
    "            print(item_number, \"batches, and LR:\", optimizer.param_groups[0]['lr'])\n",
    "\n",
    "            for i, aspect in enumerate(model.get_aspect_words(vectorizer)):\n",
    "                print(i + 1, \" \".join([a for a in aspect]))\n",
    "\n",
    "            print(\"Loss:\", loss.item())\n",
    "            print()\n",
    "\n",
    "        train_bar.update()\n",
    "    epoch_bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
