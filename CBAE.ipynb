{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import codecs\n",
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentences:\n",
    "    def __init__(self, filename: str):\n",
    "        self.filename = filename\n",
    "        self.num_lines = sum(1 for line in open(filename))\n",
    "\n",
    "    def __iter__(self):\n",
    "        for line in tqdm(\n",
    "            codecs.open(self.filename, \"r\", encoding=\"utf-8\"), \n",
    "            self.filename, \n",
    "            self.num_lines\n",
    "        ):\n",
    "            yield line.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_batches(path, batch_size=50, minlength=5):\n",
    "    \"\"\"\n",
    "        Reading batched texts of given min. length\n",
    "    :param path: path to the text file ``one line -- one normalized sentence''\n",
    "    :return: batches iterator\n",
    "    \"\"\"\n",
    "    batch = []\n",
    "\n",
    "    for line in open(path, encoding=\"utf-8\"):\n",
    "        line = line.strip().split()\n",
    "\n",
    "        # lines with less than `minlength` words are omitted\n",
    "        if len(line) >= minlength:\n",
    "            batch.append(line)\n",
    "            if len(batch) >= batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "\n",
    "    if len(batch) > 0:\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_batches(path, batch_size=50, minlength=5):\n",
    "    count = 0\n",
    "    batch_count = 0\n",
    "    \n",
    "    for line in open(path, encoding=\"utf-8\"):\n",
    "        \n",
    "        if len(line) >= minlength:\n",
    "            batch_count += 1\n",
    "            if batch_count >= batch_size:\n",
    "                count += 1\n",
    "                batch_count = 0\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vectors(text, w2v_model, maxlen, vocabulary):\n",
    "    \"\"\"\n",
    "        Token sequence -- to a list of word vectors;\n",
    "        if token not in vocabulary, it is skipped; the rest of\n",
    "        the slots up to `maxlen` are replaced with zeroes\n",
    "    :param text: list of tokens\n",
    "    :param w2v_model: gensim w2v model\n",
    "    :param maxlen: max. length of the sentence; the rest is just cut away\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    acc_vecs = []\n",
    "\n",
    "    for word in text:\n",
    "        if word in w2v_model.wv and (vocabulary is None or word in vocabulary):\n",
    "            acc_vecs.append(w2v_model.wv[word])\n",
    "\n",
    "    # padding for consistent length with ZERO vectors\n",
    "    if len(acc_vecs) < maxlen:\n",
    "        acc_vecs.extend([np.zeros(w2v_model.vector_size)] * (maxlen - len(acc_vecs)))\n",
    "\n",
    "    return acc_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_tensors(\n",
    "    path, \n",
    "    batch_size=50, \n",
    "    vocabulary=None,\n",
    "    maxlen=100, \n",
    "    pad_value=0, \n",
    "    minsentlength=5,\n",
    "    w2v_model=None,\n",
    "):\n",
    "    \"\"\"\n",
    "        Data for training the NN -- from text file to word vectors sequences batches\n",
    "    :param path:\n",
    "    :param batch_size:\n",
    "    :param vocabulary:\n",
    "    :param maxlen:\n",
    "    :param pad_value:\n",
    "    :param minsentlength:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for batch in read_data_batches(path, batch_size, minsentlength):\n",
    "        batch_vecs = []\n",
    "        batch_texts = []\n",
    "\n",
    "        for text in batch:\n",
    "            vectors_as_list = text2vectors(text, w2v_model, maxlen, vocabulary)\n",
    "            batch_vecs.append(np.asarray(vectors_as_list[:maxlen], dtype=np.float32))\n",
    "            batch_texts.append(text)\n",
    "\n",
    "        yield np.stack(batch_vecs, axis=0), batch_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroids(w2v_model, aspects_count):\n",
    "    \"\"\"\n",
    "        Clustering all word vectors with K-means and returning L2-normalizes\n",
    "        cluster centroids; used for ABAE aspects matrix initialization\n",
    "    \"\"\"\n",
    "\n",
    "    km = MiniBatchKMeans(n_clusters=aspects_count, verbose=0, n_init=100)\n",
    "    m = []\n",
    "\n",
    "    for k in w2v_model.wv.vocab:\n",
    "        m.append(w2v_model.wv[k])\n",
    "\n",
    "    m = np.matrix(m)\n",
    "\n",
    "    km.fit(m)\n",
    "    clusters = km.cluster_centers_\n",
    "\n",
    "    # L2 normalization\n",
    "    norm_aspect_matrix = clusters / np.linalg.norm(clusters, axis=-1, keepdims=True)\n",
    "\n",
    "    return norm_aspect_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenseDataset(Dataset):\n",
    "    def __init__(self, df, vectorizer, maxlen):\n",
    "        self.df = df\n",
    "        self._vectorizer = vectorizer\n",
    "        self.maxlen = maxlen\n",
    "        \n",
    "        self.train_df = self.df[self.df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "        \n",
    "        self.val_df = self.df[self.df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "        \n",
    "        self._lookup_dict = {\n",
    "            'train': (self.train_df, self.train_size),\n",
    "            'val': (self.val_df, self.validation_size),\n",
    "        }\n",
    "        \n",
    "        self.set_split('train')\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, df, maxlen):\n",
    "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
    "\n",
    "        \"\"\"\n",
    "        train_df = df[df.split=='train']\n",
    "        sentences = [s.split() for s in train_df['sentences']]\n",
    "\n",
    "#         w2v = gensim.models.Word2Vec(\n",
    "#             sentences, \n",
    "#             size=args.w2v_size, \n",
    "#             window=args.w2v_window, \n",
    "#             min_count=args.w2v_min_count, \n",
    "#             workers=args.w2v_workers, \n",
    "#             sg=args.w2v_sg,\n",
    "#             negative=args.w2v_negative, \n",
    "#             iter=args.w2v_iter, \n",
    "#             max_vocab_size=args.w2v_max_vocab_size,\n",
    "#         )\n",
    "#         w2v.save(args.w2v_file)\n",
    "\n",
    "        w2v = gensim.models.Word2Vec.load(args.w2v_file)\n",
    "\n",
    "        return cls(df, w2v, maxlen)\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        \"\"\" selects the splits in the dataset using a column in the dataframe \n",
    "        \n",
    "        Args:\n",
    "            split (str): one of \"train\", \"val\", or \"test\"\n",
    "        \"\"\"\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "        \n",
    "    def get_vectorizer(self):\n",
    "        return self._vectorizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"the primary entry point method for PyTorch datasets\n",
    "        \n",
    "        Args:\n",
    "            index (int): the index to the data point \n",
    "        Returns:\n",
    "            a dictionary holding the data point's features (x_data) and label (y_target)\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "         \n",
    "        vectors_as_list = text2vectors(row.sentences, self._vectorizer, self.maxlen, None)\n",
    "        vector = np.asarray(vectors_as_list[:self.maxlen], dtype=np.float32)\n",
    "\n",
    "        return {\n",
    "            'x_data': vector,\n",
    "            'y_target': 0.,\n",
    "        }\n",
    "    \n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int)\n",
    "        Returns:\n",
    "            number of batches in the dataset\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(dataset, batch_size, shuffle=True, drop_last=True, device=\"cpu\"):\n",
    "    \"\"\"A generator function which wraps the PyTorch DataLoader. \n",
    "    \n",
    "    It will ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle, \n",
    "        drop_last=drop_last\n",
    "    )\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_conv_output(input_, kernel, padding, stride):\n",
    "    \"\"\"Calculate the Output size in Convolution layer\n",
    "    \n",
    "    \"\"\"\n",
    "    return math.floor(((input_ - kernel + 2 * padding) / stride) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ConvLayer(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
    "#         super(ConvLayer, self).__init__()\n",
    "\n",
    "#         self.conv = nn.Conv1d(\n",
    "#             in_channels=in_channels,\n",
    "#             out_channels=out_channels,\n",
    "#             kernel_size=kernel_size,\n",
    "#             stride=stride,\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return F.relu(self.conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
    "        super(ConvLayer, self).__init__()\n",
    "\n",
    "        self.convnet = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=in_channels, \n",
    "                out_channels=out_channels, \n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride\n",
    "            ),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaryCaps(nn.Module):\n",
    "    def __init__(self, num_capsules, in_channels, out_channels, kernel_size, stride, conv_out_size):\n",
    "        super(PrimaryCaps, self).__init__()\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.capsules = nn.ModuleList([\n",
    "            nn.Conv1d(\n",
    "                in_channels=in_channels, \n",
    "                out_channels=out_channels, \n",
    "                kernel_size=kernel_size, \n",
    "                stride=stride, \n",
    "                padding=0\n",
    "            ) \n",
    "            for _ in range(num_capsules)\n",
    "        ])\n",
    "        \n",
    "        self._out_channels = out_channels\n",
    "        self._conv_out_size = conv_out_size\n",
    "    \n",
    "    def forward(self, x):\n",
    "        u = [capsule(x) for capsule in self.capsules]\n",
    "        u = torch.stack(u, dim=1)\n",
    "        u = u.view(x.size(0), self._out_channels * self._conv_out_size , -1)\n",
    "        return self.squash(u)\n",
    "    \n",
    "    def squash(self, input_tensor):\n",
    "        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n",
    "        output_tensor = squared_norm *  input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm + 1e-07))\n",
    "#         print(f'PrimaryCaps {((1. + squared_norm) * torch.sqrt(squared_norm))}')\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SecondaryCaps(nn.Module):\n",
    "    def __init__(self, num_capsules, num_routes, in_channels, out_channels):\n",
    "        super(SecondaryCaps, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.num_routes = num_routes\n",
    "        self.num_capsules = num_capsules\n",
    "\n",
    "        self.W = nn.Parameter(torch.randn(1, num_routes, num_capsules, out_channels, in_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = torch.stack([x] * self.num_capsules, dim=2).unsqueeze(4)\n",
    "\n",
    "        W = torch.cat([self.W] * batch_size, dim=0)\n",
    "        u_hat = torch.matmul(W, x)\n",
    "\n",
    "        b_ij = Variable(torch.zeros(1, self.num_routes, self.num_capsules, 1)).to(args.device)\n",
    "\n",
    "        num_iterations = 3\n",
    "        for iteration in range(num_iterations):\n",
    "            c_ij = F.softmax(b_ij, dim=2)\n",
    "\n",
    "            c_ij = torch.cat([c_ij] * batch_size, dim=0).unsqueeze(4)\n",
    "\n",
    "            s_j = (c_ij * u_hat).sum(dim=1, keepdim=True)\n",
    "            v_j = self.squash(s_j)\n",
    "            \n",
    "            if iteration < num_iterations - 1:\n",
    "                a_ij = torch.matmul(u_hat.transpose(3, 4), torch.cat([v_j] * self.num_routes, dim=1))\n",
    "                b_ij = b_ij + a_ij.squeeze(4).mean(dim=0, keepdim=True)\n",
    "\n",
    "        return v_j.squeeze(1)\n",
    "    \n",
    "    def squash(self, input_tensor):\n",
    "        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n",
    "        output_tensor = squared_norm *  input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm + 1e-07))\n",
    "#         print(f'SecondaryCaps {((1. + squared_norm) * torch.sqrt(squared_norm))}')\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        conv_in_ch,\n",
    "        conv_out_ch,\n",
    "        conv_kernel,\n",
    "        conv_stride,\n",
    "        prime_num_capsules,\n",
    "        prime_out_ch,\n",
    "        prime_kernel,\n",
    "        prime_stride,\n",
    "        secondary_num_capsules,\n",
    "        secondary_out_channels,\n",
    "        batch_size,\n",
    "        input_len,\n",
    "    ):\n",
    "        super(CapsNet, self).__init__()\n",
    "        \n",
    "        self.conv_layer = ConvLayer(\n",
    "            in_channels=conv_in_ch,\n",
    "            out_channels=conv_out_ch,\n",
    "            kernel_size=conv_kernel,\n",
    "            stride=conv_stride,\n",
    "        )\n",
    "        conv_layer_output = calculate_conv_output(\n",
    "            input_=input_len, \n",
    "            kernel=conv_kernel, \n",
    "            padding=0, \n",
    "            stride=conv_stride,\n",
    "        )\n",
    "        \n",
    "        prime_caps_conv_output = calculate_conv_output(\n",
    "            input_=conv_layer_output, \n",
    "            kernel=prime_kernel, \n",
    "            padding=0, \n",
    "            stride=prime_stride,\n",
    "        )\n",
    "        \n",
    "        self.primary_caps = PrimaryCaps(\n",
    "            num_capsules=prime_num_capsules, \n",
    "            in_channels=conv_out_ch, \n",
    "            out_channels=prime_out_ch, \n",
    "            kernel_size=prime_kernel, \n",
    "            stride=prime_stride,\n",
    "            conv_out_size=prime_caps_conv_output,\n",
    "        )\n",
    "        \n",
    "        self.secondary_caps = SecondaryCaps(\n",
    "            num_capsules=secondary_num_capsules,\n",
    "            num_routes=prime_caps_conv_output * prime_out_ch,\n",
    "            in_channels=prime_num_capsules,\n",
    "            out_channels=secondary_out_channels,\n",
    "\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(secondary_out_channels * secondary_num_capsules, input_len)\n",
    "        self.capsule_softmax = torch.nn.Softmax()\n",
    "\n",
    "        self._batch_size = batch_size\n",
    "        self._secondary_out_size=secondary_out_channels * secondary_num_capsules\n",
    "\n",
    "    def forward(self, data):\n",
    "        output = self.secondary_caps(self.primary_caps(self.conv_layer(data)))\n",
    "        output = output.reshape(-1, self._secondary_out_size)\n",
    "        output = F.relu(output)\n",
    "\n",
    "        output = self.fc(output)\n",
    "#         output = nn.Softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBAE(torch.nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        wv_dim, \n",
    "        asp_count,\n",
    "        ortho_reg, \n",
    "        maxlen, \n",
    "        init_aspects_matrix,\n",
    "        cn_conv_out_ch,\n",
    "        cn_conv_kernel,\n",
    "        cn_conv_stride,\n",
    "        cn_prime_num_capsules,\n",
    "        cn_prime_out_ch,\n",
    "        cn_prime_kernel,\n",
    "        cn_prime_stride,\n",
    "        cn_secondary_num_capsules,\n",
    "        cn_secondary_out_channels,\n",
    "        batch_size,\n",
    "        encoder_only=False,\n",
    "    ):\n",
    "        super(CBAE, self).__init__()\n",
    "        self.wv_dim = wv_dim\n",
    "        self.asp_count = asp_count\n",
    "        self.ortho = ortho_reg\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "        self.caps_net = CapsNet(\n",
    "            conv_in_ch=wv_dim,\n",
    "            conv_out_ch=cn_conv_out_ch,\n",
    "            conv_kernel=cn_conv_kernel,\n",
    "            conv_stride=cn_conv_stride,\n",
    "            prime_num_capsules=cn_prime_num_capsules,\n",
    "            prime_out_ch=cn_prime_out_ch,\n",
    "            prime_kernel=cn_prime_kernel,\n",
    "            prime_stride=cn_prime_stride,\n",
    "            secondary_num_capsules=cn_secondary_num_capsules,\n",
    "            secondary_out_channels=cn_secondary_out_channels,\n",
    "            batch_size=batch_size,\n",
    "            input_len=maxlen,\n",
    "        )\n",
    "        \n",
    "        self.linear_transform = torch.nn.Linear(self.wv_dim, self.asp_count)\n",
    "        self.softmax_aspects = torch.nn.Softmax()\n",
    "        self.aspects_embeddings = Parameter(torch.empty(size=(wv_dim, asp_count)))\n",
    "\n",
    "        if init_aspects_matrix is None:\n",
    "            torch.nn.init.xavier_uniform(self.aspects_embeddings)\n",
    "        else:\n",
    "            self.aspects_embeddings.data = torch.from_numpy(init_aspects_matrix.T)\n",
    "            \n",
    "        self.encoder_only = encoder_only\n",
    "\n",
    "    def get_aspects_importances(self, text_embeddings):\n",
    "        \"\"\"Takes embeddings of a sentence as input, returns attention weights\n",
    "\n",
    "        \"\"\"\n",
    "        # compute attention scores, looking at text embeddings average\n",
    "        caps_weights = self.caps_net(text_embeddings.permute(0, 2, 1))\n",
    "\n",
    "        # multiplying text embeddings by attention scores -- and summing\n",
    "        # (matmul: we sum every word embedding's coordinate with attention weights)\n",
    "        weighted_text_emb = torch.matmul(caps_weights.unsqueeze(1),  # (batch, 1, sentence)\n",
    "                                         text_embeddings  # (batch, sentence, wv_dim)\n",
    "                                         ).squeeze()\n",
    "\n",
    "        # encoding with a simple feed-forward layer (wv_dim) -> (aspects_count)\n",
    "        raw_importances = self.linear_transform(weighted_text_emb)\n",
    "\n",
    "        # computing 'aspects distribution in a sentence'\n",
    "        aspects_importances = self.softmax_aspects(raw_importances)\n",
    "\n",
    "        return caps_weights, aspects_importances, weighted_text_emb\n",
    "\n",
    "    def forward(self, text_embeddings, negative_samples_texts):\n",
    "        \n",
    "        # encoding: words embeddings -> sentence embedding, aspects importances\n",
    "        _, aspects_importances, weighted_text_emb = self.get_aspects_importances(text_embeddings)\n",
    "\n",
    "        if self.encoder_only:\n",
    "            return aspects_importances\n",
    "        else:\n",
    "            # negative samples are averaged\n",
    "            averaged_negative_samples = torch.mean(negative_samples_texts, dim=2)\n",
    "\n",
    "            # decoding: aspects embeddings matrix, aspects_importances -> recovered sentence embedding\n",
    "            recovered_emb = torch.matmul(self.aspects_embeddings, aspects_importances.unsqueeze(2)).squeeze()\n",
    "\n",
    "            # loss\n",
    "            reconstruction_triplet_loss = CBAE._reconstruction_loss(\n",
    "                weighted_text_emb,\n",
    "                recovered_emb,\n",
    "                averaged_negative_samples,\n",
    "            )\n",
    "\n",
    "            max_margin = torch.max(reconstruction_triplet_loss, torch.zeros_like(reconstruction_triplet_loss))\n",
    "\n",
    "            return self.ortho * self._ortho_regularizer() + max_margin\n",
    "\n",
    "    @staticmethod\n",
    "    def _reconstruction_loss(text_emb, recovered_emb, averaged_negative_emb):\n",
    "\n",
    "        positive_dot_products = torch.matmul(text_emb.unsqueeze(1), recovered_emb.unsqueeze(2)).squeeze()\n",
    "        negative_dot_products = torch.matmul(averaged_negative_emb, recovered_emb.unsqueeze(2)).squeeze()\n",
    "        reconstruction_triplet_loss = torch.sum(1 - positive_dot_products.unsqueeze(1) + negative_dot_products, dim=1)\n",
    "\n",
    "        return reconstruction_triplet_loss\n",
    "\n",
    "    def _ortho_regularizer(self):\n",
    "        return torch.norm(\n",
    "            torch.matmul(self.aspects_embeddings.t(), self.aspects_embeddings) \\\n",
    "            - torch.eye(self.asp_count).to(args.device))\n",
    "\n",
    "    def get_aspect_words(self, w2v_model, topn=10):\n",
    "        words = []\n",
    "\n",
    "        # getting aspects embeddings\n",
    "        aspects = self.aspects_embeddings.cpu().detach().numpy()\n",
    "\n",
    "        # getting scalar products of word embeddings and aspect embeddings;\n",
    "        # to obtain the ``probabilities'', one should also apply softmax\n",
    "        words_scores = w2v_model.wv.vectors.dot(aspects)\n",
    "\n",
    "        for row in range(aspects.shape[1]):\n",
    "            argmax_scalar_products = np.argsort(- words_scores[:, row])[:topn]\n",
    "            # print([w2v_model.wv.index2word[i] for i in argmax_scalar_products])\n",
    "            # print([w for w, dist in w2v_model.similar_by_vector(aspects.T[row])[:topn]])\n",
    "            words.append([w2v_model.wv.index2word[i] for i in argmax_scalar_products])\n",
    "\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        \n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "        \n",
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "\n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "\n",
    "        # If loss worsened\n",
    "        if loss_t >= train_state['early_stopping_best_val']:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    data='preprocessed_data/restaurant/train.txt',\n",
    "    test_data='preprocessed_data/restaurant/test.txt',\n",
    "    test_labels='preprocessed_data/restaurant/test_label.txt',\n",
    "    model_state_file=\"model.pth\",\n",
    "    save_dir=\"model_storage\",\n",
    "    \n",
    "    perc_train=0.95,\n",
    "    perc_val=0.05,\n",
    "\n",
    "    w2v_file='preprocessed_data/restaurant/w2v_embedding',\n",
    "    w2v_size=200,\n",
    "    w2v_window=5,\n",
    "    w2v_min_count=3,\n",
    "    w2v_workers=7,\n",
    "    w2v_sg=1,\n",
    "    w2v_negative=5,\n",
    "    w2v_iter=1,\n",
    "    w2v_max_vocab_size=9000,\n",
    "\n",
    "    batch_size=64,\n",
    "    aspects_number=14,\n",
    "    ortho_reg=0.1,\n",
    "    epochs=3,\n",
    "    optimizer='adam',\n",
    "    neg_samples=20,\n",
    "    maxlen=32,\n",
    "    minsentlength=1,\n",
    "\n",
    "    cn_conv_out_channels = 128,\n",
    "    cn_conv_kernel = 5,\n",
    "    cn_conv_stride = 1,\n",
    "    cn_prime_num_capsules=6,\n",
    "    cn_prime_kernel=3,\n",
    "    cn_prime_out_channels=32,\n",
    "    cn_prime_stride=1,\n",
    "    cn_secondary_num_capsules=8,\n",
    "    cn_secondary_out_channels=16,\n",
    "\n",
    "    cuda=True,\n",
    "    reload_from_files=False,\n",
    "    seed=1234,\n",
    "    learning_rate=1e-03 * 5,\n",
    "    early_stopping_criteria=5,  \n",
    "    catch_keyboard_interrupt=True\n",
    ")\n",
    "\n",
    "assert args.perc_val + args.perc_train == 1.0\n",
    "\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "handle_dirs(args.save_dir)\n",
    "    \n",
    "print(\"Using CUDA: {}\".format(args.cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if args.reload_from_files:\n",
    "#     print(\"Loading vectorizer\")\n",
    "# else:\n",
    "#     print(\"Loading dataset and creating vectorizer\")\n",
    "#     sentences = Sentences(args.data)\n",
    "#     w2v = gensim.models.Word2Vec(\n",
    "#         sentences, \n",
    "#         size=args.w2v_size, \n",
    "#         window=args.w2v_window, \n",
    "#         min_count=args.w2v_min_count, \n",
    "#         workers=args.w2v_workers, \n",
    "#         sg=args.w2v_sg,\n",
    "#         negative=args.w2v_negative, \n",
    "#         iter=args.w2v_iter, \n",
    "#         max_vocab_size=args.w2v_max_vocab_size,\n",
    "#     )\n",
    "#     w2v.save(args.w2v_file)\n",
    "#     print(f'{args.w2v_file} saved')\n",
    "    \n",
    "# vectorizer = gensim.models.Word2Vec.load(args.w2v_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed7540ebc054108bb5cf645415b772c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='preprocessed_data/restaurant/train.txt', max=279885.0, st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "157\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8aa2bb890b48f58d9d3d1d800f8689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='preprocessed_data/restaurant/train.txt', max=279885.0, st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>veal chop still make mouth water</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>well alot ignored</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>like glorified pizza joint sell slice</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>true traditional form southern germany history...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ambiance beat</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  split\n",
       "0                   veal chop still make mouth water  train\n",
       "1                                  well alot ignored  train\n",
       "2              like glorified pizza joint sell slice  train\n",
       "3  true traditional form southern germany history...  train\n",
       "4                                      ambiance beat  train"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_len = 0\n",
    "\n",
    "for s in Sentences(args.data):\n",
    "    if len(s) >= sentence_len:\n",
    "        sentence_len = len(s)\n",
    "        \n",
    "print(sentence_len)\n",
    "\n",
    "data = [' '.join(s) for s in Sentences(args.data)]\n",
    "split = []\n",
    "np.random.shuffle(data)\n",
    "n_train = int(len(data) * args.perc_train)\n",
    "\n",
    "for _ in range(n_train):\n",
    "    split.append('train')\n",
    "\n",
    "for _ in range(n_train, len(data)):\n",
    "    split.append('val')\n",
    "\n",
    "df = pd.DataFrame(data={'sentences': data, 'split': split})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SentenseDataset.load_dataset_and_make_vectorizer(df, args.maxlen)\n",
    "vectorizer = dataset.get_vectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bill ['tip', 'tab', 'gratuity', 'charged', '300', 'fee', 'charge', 'minimum', 'paid', '400']\n",
      "waiter ['waitress', 'server', 'manager', 'waitstaff', 'hostess', 'waitor', 'maitre', 'host', 'busboy', 'question']\n",
      "vodka ['ginger', 'mango', 'watermelon', 'pomegranate', 'rum', 'pear', 'cranberry', 'infused', 'honey', 'pineapple']\n",
      "meat ['fish', 'vegetable', 'beef', 'fat', 'cut', 'veggie', 'seafood', 'bone', 'patty', 'sliced']\n"
     ]
    }
   ],
   "source": [
    "for word in [\"bill\", \"waiter\", \"vodka\", \"meat\"]:\n",
    "    if word in vectorizer.wv.vocab:\n",
    "        print(word, [w for w, c in vectorizer.wv.similar_by_word(word=word)])\n",
    "    else:\n",
    "        print(word, \"not in vocab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_dim = vectorizer.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CBAE(\n",
    "    wv_dim=wv_dim,\n",
    "    asp_count=args.aspects_number,\n",
    "    ortho_reg=args.ortho_reg, \n",
    "    maxlen=args.maxlen, \n",
    "    init_aspects_matrix=get_centroids(vectorizer, aspects_count=args.aspects_number),\n",
    "    cn_conv_out_ch=args.cn_conv_out_channels,\n",
    "    cn_conv_kernel=args.cn_conv_kernel,\n",
    "    cn_conv_stride=args.cn_conv_stride,\n",
    "    cn_prime_num_capsules=args.cn_prime_num_capsules,\n",
    "    cn_prime_out_ch=args.cn_prime_out_channels,\n",
    "    cn_prime_kernel=args.cn_prime_kernel,\n",
    "    cn_prime_stride=args.cn_prime_stride,\n",
    "    cn_secondary_num_capsules=args.cn_secondary_num_capsules,\n",
    "    cn_secondary_out_channels=args.cn_secondary_out_channels,\n",
    "    batch_size=args.batch_size,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(args.device)\n",
    "loss_func = torch.nn.MSELoss(reduction=\"sum\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                           mode='min', factor=0.5,\n",
    "                                           patience=1)\n",
    "\n",
    "train_state = make_train_state(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df62ed8319c4bb08c3f0ea28255ae4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='training routine', max=3.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9be7f90a0aa47cb805c18f1b82920ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='split=train', max=4154.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0293c053c7450abacb4747d3d510c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='split=val', max=218.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-f0c891973f7d>:71: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  aspects_importances = self.softmax_aspects(raw_importances)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217 batches, and LR: 0.005\n",
      "0 bland dry sweet like sauce worth salty rude par tasteless\n",
      "1 feel french review cuisine anything home italian italy indian york\n",
      "2 margarita service bartender staff server waiter waitstaff crust guacamole sangria\n",
      "3 village thai crispy crab pork meat flavor bean noodle asian\n",
      "4 sauce tomato potato garlic chicken bean onion pepper spicy fried\n",
      "5 u manager table asked waiter minute hostess waitress party seat\n",
      "6 sum mexican trendy isn serf authentic comfort indian beat bbq\n",
      "7 sure reservation didn told said advance asked 15 going couldn\n",
      "8 wall wood ceiling brick lit white floor window booth chair\n",
      "9 lived visited rib stumbled wall de went gras street ago\n",
      "10 east west street garden park ave day floor visit stumbled\n",
      "11 chocolate banana cake ice apple room cream pudding strawberry fruit\n",
      "12 rude review attitude slow reviewer management poor customer credit rating\n",
      "13 ordered salad chicken entree appetizer size shared fixe grilled served\n",
      "Loss: 11.44924545288086\n",
      "\n",
      "217 batches, and LR: 0.005\n",
      "0 bland dry sweet like sauce salty rude worth tasteless par\n",
      "1 feel cuisine review french home anything italian italy fare indian\n",
      "2 margarita service bartender staff server waiter crust waitstaff guacamole sangria\n",
      "3 pork crispy fried crab bean onion crust spicy potato flavor\n",
      "4 sauce tomato garlic potato chicken onion bean pepper fried spicy\n",
      "5 u manager table waiter asked minute seat waitress hostess didn\n",
      "6 sum serf mexican bbq dim comfort indian crust fare quality\n",
      "7 sure reservation going every come advance last didn long 15\n",
      "8 wall wood ceiling brick lit white floor window booth chair\n",
      "9 chocolate street give wall stumbled go went ice bring cafe\n",
      "10 east west street park ave garden stumbled visit avenue floor\n",
      "11 chocolate cake banana ice apple cream room pudding fruit strawberry\n",
      "12 rude attitude review slow reviewer management poor credit customer card\n",
      "13 ordered chicken size entree salad appetizer fixe per beef shared\n",
      "Loss: 1.7685937881469727\n",
      "\n",
      "217 batches, and LR: 0.005\n",
      "0 dry bland sweet like potato sauce tomato onion mouth tasteless\n",
      "1 feel french cuisine home old review italy italian cooking york\n",
      "2 margarita service bartender staff server waiter crust waitstaff cooked waitress\n",
      "3 gras tuna pork wood roasted tomato bass seared grilled wall\n",
      "4 sauce tomato potato garlic chicken onion bean pepper mashed spicy\n",
      "5 year waitress decor waiter found opened charming walked stumbled italy\n",
      "6 sum crust fare bbq dim asian rib beef serf flavorful\n",
      "7 sure reservation going trip every come long advance coming last\n",
      "8 wall wood ceiling brick white lit booth window chair floor\n",
      "9 chocolate old give spot visiting went last birthday made de\n",
      "10 went best stumbled park ave garden street worst avenue square\n",
      "11 chocolate cake banana apple cream room fruit pudding tart creme\n",
      "12 rude attitude poor management customer slow credit wait review money\n",
      "13 ordered chicken size served salad shared sized per arrived three\n",
      "Loss: 9.039711952209473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epoch_bar = tqdm(\n",
    "    desc='training routine', \n",
    "    total=args.epochs,\n",
    "    position=1,\n",
    ")\n",
    "\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm(\n",
    "    desc='split=train',\n",
    "    total=dataset.get_num_batches(args.batch_size), \n",
    "    position=1, \n",
    ")\n",
    "\n",
    "dataset.set_split('val')\n",
    "val_bar = tqdm(\n",
    "    desc='split=val',\n",
    "    total=dataset.get_num_batches(args.batch_size), \n",
    "    position=1, \n",
    "    leave=True\n",
    ")\n",
    "\n",
    "for epoch_index in range(args.epochs):\n",
    "    \n",
    "    train_state['epoch_index'] = epoch_index\n",
    "    \n",
    "    # Iterate over training dataset\n",
    "    # setup: batch generator, set loss to 0, set train mode on\n",
    "    dataset.set_split('train')\n",
    "\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "\n",
    "    batch_generator = generate_batches(\n",
    "        dataset, \n",
    "        batch_size=args.batch_size, \n",
    "        device=args.device\n",
    "    )\n",
    "    \n",
    "    neg_batch_generator = generate_batches(\n",
    "        dataset, \n",
    "        batch_size=args.batch_size, \n",
    "        shuffle=False,\n",
    "        device=args.device\n",
    "    )\n",
    "\n",
    "    for batch_index, batch_dict in enumerate(batch_generator):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x = batch_dict['x_data']\n",
    "        y = batch_dict['y_target'].float()\n",
    "        x_neg = next(neg_batch_generator)['x_data']\n",
    "\n",
    "        # extracting bad samples from the very same batch; not sure if this is OK, so todo\n",
    "        negative_samples = torch.stack(\n",
    "            tuple([x_neg[torch.randperm(x_neg.shape[0])[:args.neg_samples]] \n",
    "                   for _ in range(args.batch_size)])\n",
    "        ).to(args.device)\n",
    "\n",
    "        # prediction\n",
    "        y_pred = model(x, negative_samples)\n",
    "        \n",
    "        # error computation\n",
    "        loss = loss_func(y_pred, y)\n",
    "        loss_t = loss.item()\n",
    "        \n",
    "        # compute the running loss\n",
    "        running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "        \n",
    "        # use loss to produce gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # use optimizer to take gradient step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # update bar\n",
    "        train_bar.set_postfix(loss=running_loss, epoch=epoch_index)\n",
    "        train_bar.update()\n",
    "           \n",
    "\n",
    "    train_state['train_loss'].append(running_loss)\n",
    "    \n",
    "    # Iterate over val dataset\n",
    "    # setup: batch generator, set loss and acc to 0; set eval mode on\n",
    "    dataset.set_split('val')\n",
    "    batch_generator = generate_batches(\n",
    "        dataset, \n",
    "        batch_size=args.batch_size, \n",
    "        device=args.device,\n",
    "    )\n",
    "    \n",
    "    neg_batch_generator = generate_batches(\n",
    "        dataset, \n",
    "        batch_size=args.batch_size, \n",
    "        shuffle=False,\n",
    "        device=args.device\n",
    "    )\n",
    "\n",
    "    running_loss = 0.\n",
    "    model.eval()\n",
    "\n",
    "    for batch_index, batch_dict in enumerate(batch_generator):\n",
    "        x = batch_dict['x_data']\n",
    "        y = batch_dict['y_target'].float()\n",
    "\n",
    "        negative_samples = torch.stack(\n",
    "            tuple([x_neg[torch.randperm(x_neg.shape[0])[:args.neg_samples]] \n",
    "                   for _ in range(args.batch_size)])\n",
    "        ).to(args.device)\n",
    "\n",
    "        y_pred = model(x, negative_samples)\n",
    "        \n",
    "        # compute the loss\n",
    "        loss = loss_func(y_pred, y)\n",
    "        loss_t = loss.item()\n",
    "        running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "        val_bar.set_postfix(loss=running_loss, epoch=epoch_index)\n",
    "        val_bar.update()\n",
    "    \n",
    "    train_state['val_loss'].append(running_loss)\n",
    "    train_state = update_train_state(args=args, model=model, train_state=train_state)\n",
    "\n",
    "    scheduler.step(train_state['train_loss'][-1])\n",
    "        \n",
    "    print(batch_index, \"batches, and LR:\", optimizer.param_groups[0]['lr'])\n",
    "    for i, aspect in enumerate(model.get_aspect_words(vectorizer)):\n",
    "        print(i, \" \".join([a for a in aspect]))\n",
    "    print(\"Loss:\", loss.item())\n",
    "    print()\n",
    "    \n",
    "    if train_state['stop_early']:\n",
    "        break\n",
    "\n",
    "    train_bar.n = 0\n",
    "    val_bar.n = 0\n",
    "\n",
    "    epoch_bar.set_postfix(best_val=train_state['early_stopping_best_val'])\n",
    "    epoch_bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(train_state['model_filename']))\n",
    "model = model.to(args.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-f0c891973f7d>:71: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  aspects_importances = self.softmax_aspects(raw_importances)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.encoder_only = True\n",
    "\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    data_iterator = read_data_tensors(\n",
    "        args.test_data,\n",
    "        batch_size=50, \n",
    "        maxlen=args.maxlen,\n",
    "        w2v_model=vectorizer,\n",
    "        minsentlength=0\n",
    "    )\n",
    "\n",
    "    for batch_index, (x, texts) in enumerate(data_iterator):\n",
    "        x = torch.from_numpy(x).to(args.device)\n",
    "\n",
    "        y_pred = model(x, None)\n",
    "        \n",
    "        for pred in y_pred:\n",
    "            predictions.append(pred.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "for pred in predictions:\n",
    "    classes.append(pred.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcea63f7b4bf4cb0b16cfd1df6ce6f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='preprocessed_data/restaurant/test_label.txt', max=1490.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "target = [v[0] for v in Sentences(args.test_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1490\n",
      "1490\n",
      "Counter({5: 577, 3: 455, 9: 334, 2: 50, 6: 33, 1: 16, 11: 12, 13: 9, 7: 3, 0: 1})\n",
      "Counter({'Food': 887, 'Staff': 352, 'Ambience': 251})\n"
     ]
    }
   ],
   "source": [
    "print(len(classes))\n",
    "print(len(target))\n",
    "print(Counter(classes))\n",
    "print(Counter(target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bland dry sweet like sauce salty rude worth tasteless par\n",
      "1 feel cuisine review french home anything italian italy fare indian\n",
      "2 margarita service bartender staff server waiter crust waitstaff guacamole sangria\n",
      "3 pork crispy fried crab bean onion crust spicy potato flavor\n",
      "4 sauce tomato garlic potato chicken onion bean pepper fried spicy\n",
      "5 u manager table waiter asked minute seat waitress hostess didn\n",
      "6 sum serf mexican bbq dim comfort indian crust fare quality\n",
      "7 sure reservation going every come advance last didn long 15\n",
      "8 wall wood ceiling brick lit white floor window booth chair\n",
      "9 chocolate street give wall stumbled go went ice bring cafe\n",
      "10 east west street park ave garden stumbled visit avenue floor\n",
      "11 chocolate cake banana ice apple cream room pudding fruit strawberry\n",
      "12 rude attitude review slow reviewer management poor credit customer card\n",
      "13 ordered chicken size entree salad appetizer fixe per beef shared\n"
     ]
    }
   ],
   "source": [
    "for i, aspect in enumerate(model.get_aspect_words(vectorizer)):\n",
    "    print(i, \" \".join([a for a in aspect]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_map = {\n",
    "    0: 'Food', \n",
    "    1: 'Ambience', \n",
    "    2: 'Staff', \n",
    "    3: 'Food',\n",
    "    4: 'Food', \n",
    "    5: 'Staff', \n",
    "    6: 'Ambience',  \n",
    "    7: 'Ambience', \n",
    "    8: 'Ambience', \n",
    "    9: 'Ambience', \n",
    "    10: 'Ambience', \n",
    "    11: 'Food', \n",
    "    12: 'Ambience', \n",
    "    13: 'Ambience'\n",
    "}\n",
    "\n",
    "labels = ['Ambience', 'Food', 'Miscellaneous', 'Price', 'Staff']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [cluster_map[pred] for pred in classes]\n",
    "y_true = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Ambience       0.05      0.08      0.06       251\n",
      "        Food       0.57      0.30      0.39       887\n",
      "       Staff       0.43      0.76      0.55       352\n",
      "\n",
      "    accuracy                           0.37      1490\n",
      "   macro avg       0.35      0.38      0.33      1490\n",
      "weighted avg       0.45      0.37      0.37      1490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
